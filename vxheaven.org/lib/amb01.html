<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>Matt Bishop 'An Overview of Computer Viruses in a Research Environment' (VX heaven)</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8"/>
<meta name="Author" content="Matt Bishop"/>
<meta name="KeyWords" lang="en" content="computer virus, virus, virii,vx, компьютерные вирусы, вирус, вири, Bishop, Matt,Overview of Computer Viruses in a Research Environment, computer, security, ﬁles, privileged, terminal, users, malicious, viruses, national, level, risks, subject, program, horse, memory"/>
<meta name="Description" content="The threat of attack by computer viruses is in reality a very small part of a much more general threat, speciﬁcally attacks aimed at subverting computer security. This paper examines computer viruses as malicious logic in a research and development environment, relates them to various models of security and integrity, and examines current research techniques aimed at controlling the threats viruses in particular, and malicious logic in general, pose to computer systems. Finally, a brief examination of the vulnerabilities of research and development systems that malicious logic and computer viruses may exploit is undertaken."/>
<script type="text/javascript">
//<![CDATA[
try{if (!window.CloudFlare) {var CloudFlare=[{verbose:0,p:0,byc:0,owlid:"cf",bag2:1,mirage2:0,oracle:0,paths:{cloudflare:"/cdn-cgi/nexp/dok3v=1613a3a185/"},atok:"047a5bcbf67431883fc9ed25fba33612",petok:"99c7b4d736e8a0c14be90dc5bc41605fc1292cb2-1498756910-1800",zone:"vxheaven.org",rocket:"a",apps:{}}];document.write('<script type="text/javascript" src="//ajax.cloudflare.com/cdn-cgi/nexp/dok3v=85b614c0f6/cloudflare.min.js"><'+'\/script>');}}catch(e){};
//]]>
</script>
<link rel="icon" href="/favicon.ico" type="image/x-icon"/>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"/>
<link rel="stylesheet" type="text/css" href="/style.css"/><link rel="canonical" href="http://vxheaven.org/lib/amb01.html"/>
<script type="text/rocketscript" data-rocketsrc="https://apis.google.com/js/plusone.js">{"parsetags": "explicit"}</script>
</head>
<body bgcolor="#dbc8a0" text="#302000" link="#225599" vlink="#113366">
<div class="s1">
<div style="float:right;"><a href="/lib/index.php?tbs=1"><img src="/img/max.gif" alt="Maximize"/></a></div> <form id="lf" style="margin: 0; float: right;" method="get" action="/index.php"><input type="hidden" name="action" value="set"/><select name="lang" onchange="javascript:document.getElementById('lf').submit();"><option value="ru">Русский</option><option selected="selected" value="en">English</option><option value="ua">Українська</option><option value="de">Deutsch</option><option value="es">Español</option><option value="fr">Fran&ccedil;ais</option><option value="it">Italiano</option><option value="pl">Polski</option></select></form>
<div style="float: right;"><div id="plusone"></div></div>
<script type="text/rocketscript">gapi.plusone.render("plusone", {"size":"small","count":"true"});</script>
<div style="float: right;" class="addthis_toolbox addthis_default_style">
<script type="text/rocketscript">var addthis_config = { ui_click: true }</script>
<a style="text-decoration: none; font-size: 10pt;" href="/?action=addthis" class="addthis_button_compact">Bookmark</a>
<script type="text/rocketscript" data-rocketsrc="http://s7.addthis.com/js/250/addthis_widget.js#username=herm1t"></script>
</div>
<div style="float: right;">
<script type="text/rocketscript" data-rocketsrc="http://www.google.com/cse/brand?form=cse-search-box&amp;lang=en"></script>
<form action="/search.php" id="cse-search-box">
<input type="hidden" name="cx" value="002577580816726040001:z9_irkorydo"/>
<input type="hidden" name="cof" value="FORID:10"/>
<input type="hidden" name="ie" value="UTF-8"/>
<input type="text" name="q" size="12" value=" "/>
<input type="submit" name="sa" value="Search"/>
</form>
</div><h1><a href="/" style="text-decoration: none; color: #000000;">VX Heaven</a></h1>
<span class="nav"><a href="/lib/">Library</a> <a href="/vl.php">Collection</a> <a href="/src.php">Sources</a> <a href="/vx.php?id=eidx">Engines</a> <a href="/vx.php?id=tidx">Constructors</a> <a href="/vx.php?id=sidx">Simulators</a> <a href="/vx.php?id=uidx">Utilities</a> <a href="/links.php">Links</a> <a href="/donate.php" style="color: #706020" id="donate">Donate</a> <a href="/forum" style="text-decoration: underline;">Forum</a> </span><br clear="all"/>
</div>
<div class="s2"><h1>An Overview of Computer Viruses in a Research Environment</h1><p><a href="/lib/?lang=en&amp;author=Bishop%2C%20Matt">Matt Bishop</a><br/> <em>Technical Report: PCS-TR91-156</em><br/> <em> 1991</em></p><script type="text/rocketscript">var disqus_url = 'http://vxheaven.org/lib/amb01.html';</script><div class="ci"><a href="/lib/?ci=amb01">4</a></div><img src="/img/pdf.gif" alt="PDF"/><a href="/lib/pdf/An%20Overview%20of%20Computer%20Viruses%20in%20a%20Research%20Environment.pdf">Download</a> PDF (71.65Kb) (You need to be registered on <a href="/forum">forum</a>)<br/>[<a style="" href="/lib/?lang=EN&amp;index=AV#amb01">Back to index</a>] [<a href="/lib/amb01.html#disqus_thread">Comments</a>]<br/> 
<address>
Matt Bishop<br/>
Department of Mathematics and Computer Science<br/>
Dartmouth College, Hanover, NH 03755
</address>
<p><small>This work was supported by grants NAG2-328 and NAG2-628 from the National Aeronautics and Space Administration to Dartmouth College.</small></p>
<ul>
<li><a href="#c0">Abstract</a></li>
<li><a href="#c1">1. Introduction</a></li>
<li><a href="#c2">2. What is a Computer Virus?</a></li>
<li><a href="#c3">3. Malicious Logic, Computer Viruses, and Computer Security</a></li>
<li><a href="#c4">4. A Brief History of Computer Viruses and Related Programs</a></li>
<li><a href="#c5">5. Current Research in Malicious Logic and Computer Viruses</a>
<ul>
<li><a href="#c51">5.1. Computer Viruses Acting as Both Data and Instructions</a></li>
<li><a href="#c52">5.2. Viruses Assuming the Identity of a User</a></li>
<li><a href="#c53">5.3. Viruses Crossing Protection Domain Boundaries by Sharing.</a></li>
<li><a href="#c54">5.4. Viruses Altering Files</a></li>
<li><a href="#c55">5.5. Viruses Performing Actions Beyond Speci#cation</a></li>
<li><a href="#c56">5.6. Viruses Altering Statistical Characteristics</a></li>
</ul></li>
<li><a href="#c6">6. Vulnerabilities of Existing Research-Oriented Systems</a>
<ul>
<li><a href="#c61">6.1. Computing Base</a></li>
<li><a href="#c62">6.2. Sharing Hardware and Software</a></li>
<li><a href="#c63">6.3. Integrity of Programs</a></li>
<li><a href="#c64">6.4. Backups and Recovery</a></li>
<li><a href="#c65">6.5. The Human Factor</a></li>
<li><a href="#c66">6.6. Multiple Levels of Privilege</a></li>
<li><a href="#c67">6.7. Direct Device Access</a></li>
</ul></li>
<li><a href="#c7">7. Conclusion</a></li>
<li><a href="#c8">Acknowledgments</a></li>
<li><a href="#c9">References</a></li>
<li><a href="#ca">Sidebar 1 - The First Trojan Horse</a></li>
<li><a href="#cb">Sidebar 2 - Anatomy of a Virus</a></li>
<li><a href="#cc">Sidebar 3 - A Starting Point for Suggested Guidelines for UNIX-based Systems</a></li>
<li><a href="#cd">Sidebar 4 - Forums that Discuss Viruses</a></li>
</ul>
<h2><a name="c0"></a>Abstract</h2>
<p>The threat of attack by computer viruses is in reality a very small part of a much more general threat, speciﬁcally attacks aimed at subverting computer security. This paper examines computer viruses as malicious logic in a research and development environment, relates them to various models of security and integrity, and examines current research techniques aimed at controlling the threats viruses in particular, and malicious logic in general, pose to computer systems. Finally, a brief examination of the vulnerabilities of research and development systems that malicious logic and computer viruses may exploit is undertaken.</p>
<h2><a name="c1"></a>1. Introduction</h2>
<p>A <em>computer virus</em> is a sequence of instructions that copies itself into other programs in such a way that executing the program also executes that sequence of instructions. Rarely has something seemingly so esoteric captured the imagination of so many people; magazines from <em>Business Week</em> to the <em>New England Journal of Medicine</em> [39][48][60][72][135], books [20][22][31][40][50][67][83][90][108][124], and newspaper articles [85][91][92][94][114][128] have discussed viruses, applying the name to various types of malicious programs.</p>
<p>As a result, the term “computer virus” is often misunderstood. Worse, many who do understand it do not understand protection in computer systems, for example believing that conventional security mechanisms can prevent virus infections, or are ﬂawed because they cannot. But computer viruses use a number of well-known techniques in an unusual order; they do not employ previously-unknown methods. So, although existing computer security mechanisms were not designed speciﬁcally to counter computer viruses, many of those mechanisms were designed to deal with techniques used by computer viruses. While security mechanisms cannot prevent computer virus infections any more than they can prevent all attacks, they can impede a virus’ spread as well as make the introduction of a computer virus difﬁcult, just as they can limit the damage done in an attack, or make a successful attack very difﬁcult. This paper tries to show the precise impact of many conventional security mechanisms on computer viruses by analyzing viruses in a general framework.</p>
<p>Because the probability of encountering a computer virus and the controls available to deal with it vary widely among different environments, this paper conﬁnes itself to that environment consisting of computers running operating systems designed for research and development, such as the UNIX<sup><a href="#f1" name="b1">1</a></sup> operating system, the VAX/VMS<sup><a href="#f2" name="b2">2</a></sup> operating system, and so forth. There is already a wealth of literature on computer viruses within the personal computing world (for example, see [34][62][65][124]), and a simple risk analysis (upon which we shall later elaborate) suggests that systems designed for accounting, inventory control, and other primarily business oriented operations are less likely to be attacked by using computer viruses than by other methods. So, while some of the following discussion may be fruitfully applied to computer systems in those environments (for example, see [1]), many of the underlying assumptions of system management and administration simply do not apply to those environments.</p>
<p>First, we shall review what a computer virus is, and analyze the properties that make it a threat to computer security. Next, we present a very brief history of computer viruses and consider whether their threat is relevant to research and development systems, and if so, how. After exploring some of the research in secure systems that show promise for coping with viruses, we examine several speciﬁc areas of vulnerability in research-oriented systems. We conclude with a quick summary.</p>
<h2><a name="c2"></a>2. What is a Computer Virus?</h2>
<p>Computer viruses do not appear spontaneously [25]; an <em>attacker</em> must introduce one to the targeted computer system, usually by persuading, or tricking, someone with legitimate access into placing the virus on the system. This can readily be done using a <em>Trojan horse</em>, a program which performs a stated function while performing another, unstated and usually undesirable one (see sidebar 1).<sup><a href="#f3" name="b3">3</a></sup> For example, suppose a ﬁle used to boot a microcomputer contains a Trojan horse designed to erase a disk. When the microcomputer boots, it will execute the Trojan horse, which would erase the disk. Here, the overt function is to provide a basic operating system; the covert function is to erase the disk.</p>
<p>Many studies have shown the effectiveness of the Trojan horse attack (see [99][101], for example), and one such study [74] described a Trojan horse that reproduces itself (a <em>replicating Trojan horse</em>). If such a program infects another by inserting a copy of itself into the other ﬁle or process, it is a <em>computer virus</em>. (See sidebar 2; Leonard Adelman ﬁrst called programs with the infection property “viruses” in a computer security seminar in 1983 [25].)</p>
<p>A computer virus infects other entities during its <em>infection phase</em>, and then performs some additional (possibly null) actions during its <em>execution phase</em>. Many view the infection phase as part of the “covert” action of a Trojan horse, and consequently consider the virus to be a form of the Trojan horse [44][69]. Others treat the infection phase as “overt” and distinguish between the virus and the Trojan horse, since a virus may infect and perform no covert action [25][97]. But all agree that a virus may perform covert actions during the execution phase.</p>
<p>Like Trojan horses [39], computer viruses are instances of <em>malicious logic</em> or <em>malicious programs</em>. Other programs which may be malicious but are not computer viruses are <em>worms</em>, which copy themselves from computer to computer<sup><a href="#f4" name="b4">4</a></sup>; <em>bacteria</em>, which replicate until all available resources of the host computer are absorbed; and <em>logic bombs</em>, which are run when speciﬁc conditions, such as the date being Friday the 13th, hold.</p>
<p>Malicious logic uses the user’s rights to perform their functions; a computer virus will spread only as the user’s rights will allow it, and can only take those actions that the user may take, since operating systems cannot distinguish between intentional and unintended actions. As the programs containing viruses are shared among users, the viruses spread among those users [25][97] until all programs writable by any infected program are themselves infected [56].</p>
<h2><a name="c3"></a>3. Malicious Logic, Computer Viruses, and Computer Security</h2>
<p>A site’s <em>security policy</em> describes how users may access the computer system or information on it, and the policy’s nature depends largely on how the system is to be used. <em>Military system security policies</em> deal primarily with disclosure of information, whereas <em>commercial security policies</em> deal primarily with the integrity of data on a system.</p>
<p>Security <em>mechanisms</em> that enforce policies partition the system into <em>protection domains</em> which deﬁne the set of objects that processes may access. <em>Mandatory access controls</em> prevent processes from crossing protection domain boundaries. <em>Discretionary access controls</em> condition permission to cross domain boundaries upon both the process identity and information associated with the object to be accessed.</p>
<p>Policies using mandatory access controls to prevent disclosure deﬁne a linear ordering of security levels, and a set of classes into which information is placed. Each entity’s security classiﬁcation is deﬁned by the pair (<em>security level, set of classes</em>); the security classiﬁcation of entity <em>A dominates</em> that of entity <em>B</em> if <em>A</em>’s security level is at least that of <em>B</em> and <em>A</em>’s set of classes contains all elements of <em>B</em>’s set of classes. Then the controls usually enforce some variant of the <em>Bell-LaPadula model</em> [9]: a subject may read an object only if the subject’s security classiﬁcation dominates that of the object (the <em>simple security property</em>) and a subject may modify an object only if the object’s security classiﬁcation dominates that of the subject (the <em>*-property</em> or the <em>conﬁnement property</em>). Hence subjects may obtain information only from entities with “lower” security classiﬁcations, and may disclose information only to entities with a “higher” security classiﬁcation. These controls limit malicious logic designed to disclose information to the relevant protection domain; they do not limit malicious logic designed to corrupt information in “higher” security classiﬁcations.</p>
<p>Policies using discretionary access controls to limit disclosure assume that all processes of a given identity act with the authorization of that identity. When a program containing malicious logic is executed, the malicious logic executes with the same identity as that user’s legitimate processes. The protection mechanism has no way to distinguish between acts done for the user and acts done for the attacker by the malicious logic.</p>
<p>Policies using mandatory access controls to limit modiﬁcation of entities often implement the mathematical dual of the multilevel security model described above. Multilevel integrity models deﬁne integrity levels and classes analogous to those of the multilevel security models; then controls may enforce the <em>Biba integrity model</em> [11], which allows a subject to read an entity only if the entity’s integrity classiﬁcation dominates that of the subject (the <em>simple integrity property</em>), and a subject to modify an entity only if the subject’s integrity classiﬁcation dominates that of the entity (the <em>integrity conﬁnement property</em>). This prevents a subject from modifying data or other programs at a higher integrity level, and a subject from relying on data or other programs at a lower integrity level. Hence, malicious logic can only damage those entities with lower or equal integrity classiﬁcations.</p>
<p>Lipner has proposed using the multilevel disclosure model to enforce multilevel integrity by assigning classiﬁcations and levels to appropriate user communities [87]; however, he notes that malicious logic could “write up” and thereby infect programs or alter production data and code. Clark and Wilson have proposed an alternate model [24] in which data and programs are manipulated by well-deﬁned “transformation procedures,” these procedures having been certiﬁed by the system security ofﬁcer as complying with the site integrity policy. Hence computer viruses could only propagate among production programs if a transformation procedure which contains one is itself certiﬁed to conform to the integrity policy.</p>
<p>Policies using discretionary access controls to limit modiﬁcation of entities make the same assumptions as security policies using discretionary access controls, with similar results.</p>
<p>Systems implementing multilevel security and integrity policies usually allow some small set of trusted entities to violate the stated policy when necessary for the smooth operation of the computer system. The usefulness of whatever security model the system implements depends to a very great extent on these exceptions; for should a trusted entity attempt to abuse its power to deviate from the strict policy, little can be done. The statements describing the effects of the controls on malicious logic above apply only to the model, and must be suitably modiﬁed for those situations in which a security policy allows (trusted) entities to violate the policy.</p>
<p>The two phases of a computer virus’ execution illustrate this. Infecting (altering) a program may be possible due to an allowed exception to the site’s integrity model. Executing a computer virus to disclose some information across protection domain boundaries may also be possible because of an allowed exception to the site’s disclosure model. So the virus may spread more widely because of the allowed exceptions.</p>
<p>An alternate view of malicious logic is that it causes the altered program to deviate from its speciﬁcation. If this is considered an “error” as well as a breach of security, fault-tolerant computer systems, which are designed to continue reliable operation when errors occur, could constrain malicious logic. Designers of reliable systems place emphasis on both recovery and preventing failures [106]; however, if malicious logic discloses information or gives away rights, or controls other critical systems (such as life support systems), recovery may not be possible. So the areas of reliability and fault-tolerance are relevant to the study of malicious logic, but those areas of fault recovery are less so.</p>
<p>In the most general case, whether a given program will infect another is undecidable [2][25], so programs that look for virus infections must check characteristics of known viruses rather than rely on a general infection detection scheme. Further, viruses can be programmed to mutate, and hence be able to evade those agents, which in turn can be programmed to detect the mutations; and in the general case, whether or not one virus mutated to produce another virus is also undecidable [30].</p>
<h2><a name="c4"></a>4. A Brief History of Computer Viruses and Related Programs</h2>
<p>One of the earliest documented replicating Trojan horses was a version of the game program <em>animal</em> which when played created another copy of itself. A later version deleted one copy of the ﬁrst version, and then created two additional copies of itself. Because it spread even more rapidly than the ﬁrst version, this later program supplanted the ﬁrst entirely. After a preset date, whenever anyone played the second version, it deleted itself after the game ended [41].</p>
<p>Ken Thompson created a far more subtle replicating Trojan horse when he rigged a compiler to break login security [107][127]. When the compiler compiled the login program, it would secretly insert instructions to cause the resulting executable program to accept a ﬁxed, secret password as well as a user’s real password. Also, when compiling the compiler, the Trojan horse would insert commands to modify the login command into the resulting executable compiler. Thompson then compiled the compiler, deleted the new source, and reinstalled the old source. Since it showed no traces of being doctored, anyone examining the source would conclude the compiler was safe. Fortunately, Thompson took some pains to ensure that it did not spread further, and it was ﬁnally deleted when someone copied another version of the executable compiler over the sabotaged one. Thompson’s point was that “no amount of source-level veriﬁcation or scrutiny will protect you from using untrusted code” ([127], p. 763), which bears remembering, especially given the reliance of many security techniques relying on humans certifying programs to be free of malicious logic.</p>
<p>In 1983, Fred Cohen designed a computer virus to acquire privileges on a VAX-11/750 running UNIX; he obtained all system rights within half an hour on the average, the longest time being an hour, and the least being under 5 minutes. Because the virus did not degrade response time noticeably, most users never knew the system was under attack. In 1984 an experiment involving a UNIVAC 1108 showed that viruses could spread throughout that system too. Viruses were also written for other systems (TOPS-20<sup><a href="#f5" name="b5">5</a></sup>, VAX/VMS, and a VM/370<sup><a href="#f6" name="b6">6</a></sup> system) but testing their effectiveness was forbidden. Cohen’s experiments indicated that the security mechanisms of those systems did little if anything to inhibit computer virus propagation [25][26].</p>
<p>In 1987, Tom Duff experimented on UNIX systems with a small virus that copied itself into executable ﬁles. The virus was not particularly virulent, but when Duff placed 48 infected programs on the most heavily used machine in the computing center, the virus spread to 46 different systems and infected 466 ﬁles, including at least one system program on each computer system, within eight days. Duff did not violate the security mechanisms in any way when he seeded the original 48 programs [45]. By writing another virus in a language used by a command interpreter common to most UNIX systems, he disproved a common fallacy [50] that computer viruses are intrinsically machine dependent, and cannot spread to systems of varying architectures.</p>
<p>On November 2, 1988, a program combining elements of a computer worm and a computer virus targeting Berkeley and Sun UNIX-based computers entered the Internet; within hours, it had rendered several thousand computers unusable [46][47][109][117][118][122][123][125]. Among other techniques, this program used a virus-like attack to spread: it inserted some instructions into a running process on the target machine and arranged for those instructions to be executed. To recover, these machines had to be disconnected from the network, rebooted, and several critical programs changed and recompiled to prevent re-infection. Worse, the only way to determine if the program had other malicious side effects (such as deleting ﬁles) was to disassemble it. Fortunately, its only purpose turned out to be to propagate. Infected sites were extremely lucky that the worm<sup><a href="#f7" name="b7">7</a></sup> did not infect a system program with a virus designed to delete ﬁles, or did not attempt to damage attacked systems. Since then, there have been several incidents involving worms [59][66][125].</p>
<p>In general, though, computer viruses and replicating Trojan horses have been laboratory experiments rather than attacks from malicious or careless users. This raises a question of risk analysis: do the beneﬁts gained in defending against computer viruses offset the costs of recovery and the likelihood of being attacked?</p>
<p>As worded, the above question implies that the mechanisms defending against computer viruses are useful <em>only</em> against computer viruses. However, computer viruses use techniques that are also used in other methods of attack, such as scavenging<sup><a href="#f8" name="b8">8</a></sup>, as well as by other forms of malicious logic. Defenses which strengthen access controls to prevent illicit access, or which prevent or detect the alteration of other ﬁles, also limit, prevent, or detect these other attacks as well. So, a more appropriate question is whether the beneﬁts gained in defending against all such attacks offset the costs of recovery and the likelihood of being attacked.</p>
<p>Because this paper focuses primarily on computer viruses, we shall not delve into the history of computer security or malicious logic in general. Sufﬁce it to say that the vulnerability of computer systems to such attacks is well known, and attacks on computer systems are common enough (see both [99] and [101] for descriptions of such incidents) that the use of mechanisms to inhibit them is generally agreed to be worthwhile.</p>
<h2><a name="c5"></a>5. Current Research in Malicious Logic and Computer Viruses</h2>
<p>The effectiveness of any security mechanism depends upon the security of the underlying base on which the mechanism is implemented, and the correctness of the necessary checking done at each step. If the trust in the base or in the checking is misplaced the mechanism will not be secure. Thus “secure” is a relative notion, as is “trust,” and mechanisms to enhance computer security attempt to balance the cost of the mechanism with the level of security desired and the degree of trust in the base that the site accepts as reasonable. Research dealing with malicious logic assumes the interface, software, and/or hardware used to implement the proposed scheme performs exactly as desired, meaning the trust is in the underlying computing base, the implementation, and (if done) the veriﬁcation.</p>
<p>Current research uses speciﬁc properties of computer viruses to detect and limit their effects. Because of the fundamental nature of these properties, these defenses work equally well against most other forms of malicious logic.</p>
<h3><a name="c51"></a>5.1. Computer Viruses Acting as Both Data and Instructions</h3>
<p>Techniques exploiting this property treat all programs as type “data” until some certifying authority changes the type to “executable” (instructions). Both new systems designed to meet strong security policies and enhancements to existing systems use this method.</p>
<p>Boebert and Kain [18] have proposed labelling subjects and objects in the Logical Coprocessor Kernel or LOCK (formerly the Secure Ada Target or SAT) [17][61][112][113], a system designed to meet the highest level of security under the Department of Defense criteria [43]. Once compiled, programs have the label “data,” and cannot be executed until a sequence of speciﬁc, auditable events changes the label to “executable.” After that, the program cannot be modiﬁed. This scheme recognizes that viruses treat programs as data (when they infect them by changing the ﬁle’s contents) and as instructions (when the program executes and spreads the virus), and rigidly separates the two. The Argus Security Model [3] uses the same principle.</p>
<p>Duff [45] has suggested a variant for UNIX-based systems. Noting that users with execute permission for a ﬁle usually also have read permission, he proposes that ﬁles with execute permission be of type “executable,” and those without it be of type “data.” Unlike the LOCK, “executable” ﬁles could be modiﬁed but doing so would change the type to “data.” If the certifying authority were the omnipotent user, the virus could spread only if run as that user. To prevent infection from non-executable ﬁles, libraries and other system components of programs must also be certiﬁed before use.</p>
<p>Both the LOCK scheme and Duff’s proposal trust that the administrators will never certify a program containing malicious logic (either by accident or deliberately), and that the tools used in the certiﬁcation process are not themselves corrupt.</p>
<h3><a name="c52"></a>5.2. Viruses Assuming the Identity of a User</h3>
<p>Among the many enhancements to discretionary access controls are suggestions to allow the user to reduce the associated protection domain [29][72][121][134]; to base access to ﬁles on some characteristic of the command or program [27][81], possibly including subject authorizations as well [25]; and to use a knowledge-based subsystem to determine if a program makes reasonable ﬁle accesses [73]. Allowing users to specify semantics for ﬁle accesses [10][36] may prove useful in some contexts, for example protecting a limited set of ﬁles.</p>
<p>All such mechanisms trust the users to take explicit action to limit their protection domains sufﬁciently; or trust tables to describe the programs’ expected actions sufﬁciently for the mechanism to apply those descriptions, and the mechanism to handle commands with no corresponding table entries effectively; or they trust speciﬁc programs and the kernel, when those would be the ﬁrst programs a virus would attack.</p>
<h3><a name="c53"></a>5.3. Viruses Crossing Protection Domain Boundaries by Sharing.</h3>
<p>Inhibiting users in different protection domains from sharing programs or data will inhibit viruses from spreading among those domains. For example, when users share procedures, the LOCK keeps only one copy of the procedure in memory. A master directory, accessible only to a trusted hardware controller, associates with each procedure a unique owner, and with each user a list of others whom that user trusts. Before executing any procedure, the dynamic linker checks that the user executing the procedure trusts the procedure’s owner [16]. This scheme assumes that users’ trust in one another is always well-placed.</p>
<p>A more general proposal [137] suggests placing programs to be protected at the lowest possible level of an implementation of a multilevel security policy. Since the mandatory access controls will prevent those processes from writing to objects at lower levels, any process can read the programs but no process can write to them. Such a scheme would have to be combined with an integrity model to provide protection against viruses to prevent both disclosure and ﬁle corruption. Carrying this idea to its extreme would result in isolation of each domain; since sharing is not possible, no viruses can propagate. Unfortunately, the usefulness of such systems would be minimal.</p>
<h3><a name="c54"></a>5.4. Viruses Altering Files</h3>
<p>Mechanisms using <em>manipulation detection codes</em> (or <em>MDC</em>s) apply some function to a ﬁle to obtain a set of bits called the <em>signature block</em> and then encrypt that block. If, after recomputing the signature block and reencrypting it, the result differs from the stored signature block, the ﬁle has changed [86][95], possibly due to infection or some other cause not related to viruses.</p>
<p>An assumption is that the signed ﬁle does not contain a virus before it is signed. Page [100] has suggested expanding the model in [17] to include the software development process (in effect limiting execution domains for each development tool and user) to ensure software is not contaminated during development. Pozzo and Grey [104][105] have implemented Biba’s integrity model on the distributed operating system LOCUS [103] to make the level of trust in the above assumption explicit. They have different classes of signed executable programs. <em>Credibility ratings</em> (Biba’s “integrity levels”) assign a measure of trustworthiness on a scale of 0 (unsigned) to <em>N</em> (signed and formally veriﬁed), based on the origin of the software. Trusted ﬁle systems contain only signed executable ﬁles with the same credibility level. Associated with each user (subject) is a <em>risk level</em> that starts out as the highest credibility level. Users may execute programs with credibility levels no less than their risk level; when the credibility level is lower than the risk level, a special “run-untrusted” command must be used.</p>
<p>All integrity-based schemes rely on software which if infected may fail to report tampering. Performance will be affected as encrypting the ﬁle or computing the signature block may take a signiﬁcant amount of time. The encrypting key must also be secret, for if not then malicious logic can easily alter a signed ﬁle without the change being detected.</p>
<p>Network implementations of MDC-based mechanisms require that public keys be certiﬁed by a trusted authority and distributed in a trusted fashion (see for example [15][75]). If the key distribution mechanism used the same paths as the data transmission and the public keys were not veriﬁable using an out-of-bands method, a malicious site (or set of cooperating malicious sites) could alter the data or program being sent, recompute the signature block and sign it with its own (bogus) private key, and then transmit the data; when the public key were requested, it would simply send the one corresponding to the (bogus) private key. The more general (non-network) software distribution problem has similar requirements [35].</p>
<p>Anti-virus agents check ﬁles for speciﬁc viruses and if present either warn the user or attempt to “cure” the infection by removing the virus. Many such agents exist for personal computers, but since each must look for a particular virus or set of viruses, they are very speciﬁc tools and, because of the undecidability results stated earlier, cannot deal with viruses not yet analyzed.</p>
<h3><a name="c55"></a>5.5. Viruses Performing Actions Beyond Speciﬁcation</h3>
<p>Fault-tolerant techniques keep systems functioning correctly when the software or hardware fails to perform to speciﬁcation. Joseph and ˘Avizienis have suggested treating a virus’ infection and execution phases as errors. The ﬁrst such proposal [70][71] breaks programs into sequences of non-branching instructions, and checksums each sequence, storing the results in encrypted form. When the program is run, the processor recomputes checksums, and at each branch, a co-processor compares the computed checksum to the encrypted checksum; if they differ, an error (which may be an infection) has occurred. Later proposals advocate checking each instruction [35]. These schemes raise issues of key management and protection, as well as how much the software managing keys, transmitting the control ﬂow graph to the co-processor, and implementing the recovery mechanism, may be trusted.</p>
<p>A proposal based on <em>N-Version Programming</em> [5] requires implementing several different versions of an algorithm, running them concurrently and periodically checking intermediate results against each other. If they disagree, the value assumed correct is the intermediate value that a majority of the programs have obtained, and the programs with a different value are malfunctioning (possibly due to malicious logic). This requires a majority of the programs not to be infected, and the underlying operating system to be secure. Also, the issue of the efﬁcacy of N-version programming is highly questionable [77]. Despite claims that the method is feasible [6][23], detecting the spread of a virus would require voting upon each ﬁle system access; to achieve this level of comparison, the programs would all have to implement the same algorithm, which defeats the purpose of using N-version programming [78].</p>
<h3><a name="c56"></a>5.6. Viruses Altering Statistical Characteristics</h3>
<p>Proposals to examine the appearance of programs for identical sequences of instructions or byte patterns [69][137] require a high number of comparisons and would need to take into account the reuse of common library routines or of code [76]. Malicious logic might be present if a program appears to have more programmers than were known to have worked on it, or if one particular programmer appears to have worked on many different and unrelated programs [137]; but several assumptions must ﬁrst be validated, namely that programmers have their own individual styles of writing programs, that the executable programs generated by the compilers will reﬂect these styles, and that a <em>coding style analyzer</em> can distinguish these styles from one another. If an object ﬁle contains conditionals not corresponding to any in the source, the object may be infected [54]. A fourth proposal suggests designing a ﬁlter to detect, analyze, and classify all modiﬁcations that a program will make as ordinary or suspicious [32].</p>
<p>Finally, Dorothy Denning has suggested using an intrusion-detection expert system to detect viruses by looking for increases in the size of ﬁles, increases in the frequency of writing to executable ﬁles, or alterations in the frequency of executing a speciﬁc program in ways not matching the proﬁle of users spreading the infection [38]. Several such systems have been implemented [8][88][126] and have detected many anomalies without noticeably degrading the monitored computer. These experiments did not attempt to validate claims about detecting viruses.</p>
<p>Those research proposals that are being implemented are either targeted for speciﬁc architectures or are in the very early stages of development. This state of affairs is unsettling for the managers and administrators of existing systems, who need to take some action to protect their users and systems.</p>
<h2><a name="c6"></a>6. Vulnerabilities of Existing Research-Oriented Systems</h2>
<p>The vulnerabilities exploited by a computer virus can also be exploited by other forms of malicious logic, and unless the purpose of the attack is to cause mischief, the other forms of malicious logic are much easier to create. Rather than describe appropriate countermeasures, we simply note that these will differ from environment to environment, and no such list (or even set of lists) can accurately reﬂect the idiosyncracies of all the different research and development systems and environments; in short, providing such a generic list could give a very false sense of security.</p>
<p>This section discusses the areas of vulnerability. While we emphasize computer viruses throughout, these same vulnerabilities can be exploited by Trojan horses, computer worms, other forms of malicious logic, and, more generally, other types of attacks. We leave it to the reader to formulate appropriate techniques to detect or hinder attacks exploiting each area. (Sidebar 3 offers a starting point for UNIX-based systems.)</p>
<h3><a name="c61"></a>6.1. Computing Base</h3>
<p>Users assume that the computer system provides a set of trustworthy tools for compiling, linking and loading, and running programs. In most systems, the “trust” is the user’s estimate of the quality of the tools available [28] and the working environment. If the estimates are incorrect, the system may be subverted.</p>
<p>Even systems with security enhancements are vulnerable. One version of the UNIX operating system with security enhancements was breached when a user created a version of the directory lister, with a Trojan horse, in his home directory. He then requested assistance from the system operator, who changed to the user’s home directory, and listed the names of the ﬁles in it. As the command interpreter checked for commands in the current working directory and <em>then</em> in the system directories, the user’s doctored lister, not the system lister, was executed [120].</p>
<p>In the above, the system administrator trusted the command interpreter to look for system programs before executing programs in users’ directories. Other examples include trusting that the login banner being presented is actually from the login program and not from a user’s program which will record passwords [58], or that page faults cannot be detected while checking passwords one character at a time [82].</p>
<h3><a name="c62"></a>6.2. Sharing Hardware and Software</h3>
<p>Intimately bound with the notion of trust is the ability to share. When many computers share a copy of an infected program, every ﬁle accessible from every one of those machines can be infected. Methods of sharing include making and distributing copies of software, accessing bulletin board systems, public ﬁle servers, and obtaining source ﬁles from remote hosts using a network or electronic mail.</p>
<p>The probability of any new program containing malicious logic depends on the integrity of the author (or authors), the security and integrity of the computer on which they worked, on which the distribution was prepared, and on the method of distribution. Programs sent through electronic mail or posted to bulletin boards may be altered in transit, either by someone modifying them while they sit on an intermediate node, or while they are crossing networks [133]. Further, electronic messages can easily be forged [116][132], so it is unwise to rely on such a program’s stated origin.</p>
<p>In the early 1980s a program posted to the USENET news network contained a command to delete all ﬁles on the system in which it was run. Some system administrators executed the program with unlimited privileges, thereby damaging their systems. In another case, although vendors usually take care that their software contains no malicious logic, a company selling software for the Macintosh<sup><a href="#f9" name="b9">9</a></sup> unwittingly delivered copies of programs infected by a computer virus which printed a message asking for universal peace [51].</p>
<h3><a name="c63"></a>6.3. Integrity of Programs</h3>
<p>The infection phase of a virus’ actions require writing to ﬁles; for reasons discussed earlier, discretionary access controls provide little protection. Typically some form of auditing is used to detect changes [14][19]; however, auditing schemes cannot prevent damage, but only attempt to provide a record of it and (possibly) indicate the culprit. The best auditing methods use a mechanism that records changes to ﬁles or their characteristics. Such schemes require kernel modiﬁcations [102] and should be designed into new systems [57][79][96]; if a site has only object code, it cannot add these mechanisms and so must scan the ﬁle system [13]. Audit logs must also be protected from illicit modiﬁcation; again, an element of trust in the underlying subsystem is needed.</p>
<p>A computer virus can defeat any auditing scheme by infecting a ﬁle and then altering the ﬁle’s contents or characteristics during the audit, for example by restoring the uncorrupted version temporarily. An example of such a <em>stealth virus</em> is the 4096 (personal computer) virus [89].</p>
<p>No program can determine if an arbitrary virus has infected a ﬁle because of the undecidability results cited earlier; however, <em>virus detectors</em> or <em>anti-virus agents</em> can check ﬁles for speciﬁc virus. If a virus detector reports that no infection is present, the ﬁle may contain a virus unknown to the detector, or the detector may be corrupt. In February 1989, at Dartmouth College, a user ran an infected version of the virus detection program Interferon, infecting ﬁles on his disk. More widely known is the Trojan horse in a doctored copy of the anti-virus program FLUSHOT [64]; later versions are called FSP+ to avoid confusion with the tampered version [7].</p>
<h3><a name="c64"></a>6.4. Backups and Recovery</h3>
<p>Using backups to replace infected ﬁles, or ﬁles which contain malicious logic, may remove such programs from the system. As most systems make backup copies of ﬁles which have changed since the time the previous backup was made, it is quite likely that several backups will need to be examined to ﬁnd an uncontaminated version of the infected program. Further, unless all malicious programs are found and restored at the same time, the restoration of some uncorrupted programs may do little (for example, computer viruses still resident on the system could infect the newly-restored programs).</p>
<p>If the backup and restore programs themselves contain malicious logic that prevents uncorrupted software from being restored, then the backups are useless until a way is found to replace (or ﬁx) the restore program. Worse, some research and development systems (such as variants of the UNIX operating system) do not allow users to “lock” devices, so one user can access media mounted by another user. Thus, between the mounting and the attempt to restore, another program containing malicious logic could easily infect or erase a mounted backup.</p>
<h3><a name="c65"></a>6.5. The Human Factor</h3>
<p>It has been said that computer viruses are a management issue, because they are introduced by people [37]; the same may be said for all malicious logic, and computer security in general. Ideally, security procedures should balance the security and safety of the system and data with the needs of the users and systems personnel to get work done. All too often, users (and systems personnel) see them as burdens to be evaded. Lack of awareness of the reasons for security procedures and mechanisms leads to carelessness or negligence, which can in turn lead to system compromise (see for example [101]).</p>
<p>Little if anything can be done to prevent compromise by trusted personnel. Malicious users and system administrators can often circumvent security policy restrictions without being stopped, or even detected, by using the exceptions to the mechanisms enforcing the policies. (See [99] for examples of these “inside jobs.”) The study of computing ethics, or of a code of ethical conduct, reduces this threat by making clear what actions are considered acceptable; should a breach occur, legal remedies may be available [55][111].</p>
<h3><a name="c66"></a>6.6. Multiple Levels of Privilege</h3>
<p>Multi-user computer systems often provide many different levels of privilege; for example, UNIX provides a separate set of privileges for each user, and one all-powerful <em>superuser</em>. Enforcing the <em>principle of least privilege</em> [110] can limit the ﬁles that malicious logic can read or write.</p>
<p>If someone using a privileged account accidentally executes a program containing a computer virus, the virus will spread throughout the system rapidly [45]. Hence, simply logging in as a privileged user and remaining so empowered increases the possibility of accidentally triggering some form of malicious logic. More subtle is the use of programs which can cross protection domain boundaries; when the boundary being crossed involves the addition of a privilege or capability that enables the user to affect objects in many other protection domains (such as changing from an unprivileged to a privileged mode), a malicious program could read or alter data or programs not normally accessible to the user. In general, computer systems do not force such programs to function with as few privileges as possible. For example, the setuid and setgid mechanism of UNIX [12][21][84] violate this principle.</p>
<p>A related but widely-ignored problem is the use of “smart” terminals to access privileged accounts. These terminals will respond to control sequences from a host by transmitting portions of the text on their screen back to the host [52], and often perform simple editing functions for the host. Such a terminal can issue a computer virus’ commands in the name of the terminal’s user when appropriate text and control sequences are sent to it (for example, by using an inter-terminal communications program or displaying ﬁles with appropriate characters in it.) These commands could instruct the computer to execute an infected program, which would run in the protection domain of the user of the terminal (and not that of the attacker). As many computers use such terminals as their consoles, and allow access to the most privileged accounts only when the user is at the console, the danger is obvious.</p>
<h3><a name="c67"></a>6.7. Direct Device Access</h3>
<p>The <em>principle of complete mediation</em> [110] requires checking the validity of every access. Although multi-user systems have virtual memory protection to prevent processes from writing into each other’s memory, some represent devices and memory as addressable objects (such as ﬁles). If these objects are improperly or inadequately protected, a process could bypass the virtual memory controls and write to any location in memory by placing data and addresses on the bus, thereby altering the instructions and data in another’s memory space (the “core war” games [42] did this). If any process could write to disks without the kernel’s intervention, anyone can change executable programs regardless of their protection – and a virus can easily spread by taking advantage of the (lack of) protection.</p>
<h2><a name="c7"></a>7. Conclusion</h2>
<p>This paper has described the threats that computer viruses pose to research and development multi-user computer systems; it has attempted to tie those programs with other, usually simpler, programs that can have equally devastating effects. Although reports of malicious programs in general abound, no non-experimental computer viruses have been reported on mainframe systems.<sup><a href="#f10" name="b10">10</a></sup> Noting that the number of people with access to mainframes is relatively small compared to the number with access to personal computers [130], Highland suggests that as malicious people make up a very small fraction of all computer programmers, most likely fewer malicious people use research and development systems than personal computers [64]. A more persuasive argument, advanced by Fåk [49] and supported by Kurzban [80] is that, as only programmers can create computer viruses, and malicious mainframe programmers can accomplish their goals with less trouble than writing a computer virus, computer virus attacks will most likely be conﬁned to personal computers. Exceptions would most likely be motivated by a perceived intellectual challenge of creating a virus, by a desire to demonstrate limits of existing security mechanisms, by a desire for publicity, or attacks launched simply by carelessness or error [98].<sup><a href="#f11" name="b11">11</a></sup></p>
<p>Should an attacker use a computer virus or other malicious program, security mechanisms currently in use will be as effective as they are against other types of attacks. As with attempts to breach security in general, though, people can prepare for such an attack and minimize the damage done. This paper has described several vulnerabilities in the research and development environment that malicious programs could exploit, and also discussed research underway to improve defenses against malicious logic. How effective these new mechanisms will be in reducing the vulnerabilities, only time will tell.</p>
<h2><a name="c8"></a>Acknowledgments</h2>
<p>Thanks to Holly Bishop, Ken Bogart, André Bondi, Emily Bryant, Peter Denning, Donald Johnson, John Rushby, Eugene Spafford, Ken Van Wyk, and the anonymous referees, all of whose comments and advice improved the quality of the paper greatly. Josh Alden of the Dartmouth Virus Clinic described the Interferon infection incident, Robert Van Cleef and Gene Spafford helped reconstruct the USENET logic bomb incident, and Ken Thompson conﬁrmed that he had indeed doctored an <em>internal</em> version of the C compiler as described in [127]. My thanks to them also.</p>
<h2><a name="c9"></a>References</h2>
<ol>
<li>G. Al-Dossary, <a href="/lib/agd00.html">“Computer Virus Prevention and Containment on Mainframes,”</a> <em>Computers and Security</em> 9(2) (Apr. 1990) pp. 131-137.</li>
<li>L. Adelman, <a href="/lib/ala01.html">“An Abstract Theory of Computer Viruses,”</a>, <em>Advances in Cryptology – CRYPTO ‘88 Proceedings</em>, Springer-Verlag, New York, NY (Aug. 1988) pp. 354-374.</li>
<li>M. Adkins, G. Dolsen, J. Heaney, and J. Page, “The Argus Security Model,” <em>Twelfth National Computer Security Conference Proceedings</em> (Oct. 1989) pp. 123-134.</li>
<li>J. Anderson, “Computer Security Technology Planning Study,” ESD-TR-73-51, Air Force Electronic Systems Division, Hanscom Air Force Base, MA (1974).</li>
<li>A. Avižienis, “The N-Version Approach to Fault-Tolerant Software,” <em>IEEE Transactions on Software Engineering</em> SE-11(12) (Dec. 1985) pp. 1491-1501.</li>
<li>A. Avižienis, M. Lyu, and W. Schutz, “In Search of Effective Diversity: A Six-Language Study of Fault-Tolerant Control Software,” Technical Report CSD-870060, University of California, Los Angeles, CA (Nov. 1987).</li>
<li>D. Bader, “Bad Versions of FLUSHOT (for IBM PC),” <em>Virus-L Digest</em> 1(8) (Nov. 15, 1988).</li>
<li>D. Bauer and M. Koblentz, “NDIX – A Real-Time Intrusion Detection Expert System,” <em>1989 Summer USENIX Conference Proceedings</em> (June 1988) pp. 261-274.</li>
<li>D. Bell and L. LaPadula, “Secure Computer Systems: Uniﬁed Exposition and MULTICS Interpretation,” Technical Report MTR-2997, MITRE Corporation, Bedford, MA (July 1975).</li>
<li>B. Bershad and C. Pinkerton, “Watchdogs: Extending the UNIX File System,” <em>1988 Winter USENIX Conference Proceedings</em> (Feb. 1988) pp. 267-276.</li>
<li>K. Biba, “Integrity Considerations for Secure Computer Systems,” Technical Report ESD-TR-76-372, Air Force Electronic Systems Division, Hanscom Air Force Base, MA (1977).</li>
<li>M. Bishop, “How to Write a Setuid Program,” <em>;login:</em> 12(1) (Jan. 1987) pp. 5-11.</li>
<li>M. Bishop, “Auditing Files on a Network of UNIX Machines,” <em>Proceedings of the UNIX Security Workshop</em> (Aug. 1988) pp. 51-52.</li>
<li>M. Bishop, “A Model of Security Monitoring,” <em>Proceedings of the Fifth Annual Computer Security Applications Conference</em> (Dec. 1989) pp. 46-52.</li>
<li>M. Bishop, “An Authentication Mechanism for USENET,” <em>1991 Winter USENIX Conference Proceedings</em> (Jan. 1991) pp. 281-287.</li>
<li>W. Boebert and C. Ferguson, “A Partial Solution to the Discretionary Trojan Horse Problem,” <em>Proceedings of the Eighth Computer Security Conference</em> (sep. 1985) pp. 245-253.</li>
<li>W. Boebert and R. Kain, “A Practical Alternative to Hierarchical Integrity Policies,” <em>Proceedings of the Eighth Computer Security Conference</em> (Sep. 1985) pp. 18-27.</li>
<li>W. Boebert, W. Young, R. Kain, and S. Hansohn, “Secure Ada Target: Issues, System Design, and Veriﬁcation,” <em>Proceedings of the 1985 Symposium on Security and Privacy</em> (Apr. 1985) pp. 176-183.</li>
<li>D. Bonyun, “The Role of a Well Deﬁned Auditing Process in the Enforcement of Privacy Policy and Data Security,” <em>Proceedings of the 1981 Symposium on Security and Privacy</em> (Apr. 1981) pp. 19-25.</li>
<li>J. Brunner, <a href="/lib/mjb01.html">The Shockwave Rider</a>, Ballantine York City, NY (1975).</li>
<li>S. Bunch, “The Setuid Feature in UNIX and Security,” <em>Tenth National Computer Security Conference Proceedings</em> (Sep. 1987) pp. 245-253.</li>
<li>R. Burger, <em><a href="/lib/arb01.html">Computer Viruses – A High-Tech Disease</a></em>, Abacus, Grand Rapids, MI (1988).</li>
<li>L. Chen, “Improving Software Reliability by N-Version Programming,” Technical Report Eng-7843, University of California, Los Angeles, CA (Aug. 1978).</li>
<li>D. Clark and D. Wilson, “A Comparison of Commercial and Military Computer Security Policies,” <em>Proceedings of the 1987 Symposium on Security and Privacy</em> (Apr. 1987) pp. 184-194.</li>
<li>F. Cohen, <a href="/lib/afc01.html">“Computer Viruses: Theory and Experiments,”</a> <em>Seventh DOD/NBS Computer Security Conference Proceedings</em> (Sep. 1984) pp. 240-263.</li>
<li>F. Cohen, <a href="/lib/afc01.html">“Computer Viruses: Theory and Experiments,”</a> <em>Computers and Security</em> 6(1) (Feb. 1987) pp. 22-35.</li>
<li>F. Cohen, <a href="/lib/afc08.html">“On the Implications of Computer Viruses and Methods of Defense,”</a> <em>Computers and Security</em> 7(2) (Apr. 1988) pp. 167-184.</li>
<li>F. Cohen, “Maintaining a Poor Person’s Information Integrity,” <em>Computers and Security</em> 7(5) (Oct. 1988) pp. 489-494.</li>
<li>F. Cohen, <a href="/lib/afc07.html">“Practical Defenses Against Computer Viruses,”</a> <em>Computers and Security</em> 8(2) (Apr. 1989) pp. 149-160.</li>
<li>F. Cohen, <a href="/lib/afc10.html">“Computational Aspects of Computer Viruses,”</a> <em>Computers and Security</em> 8(4) (June 1989) pp. 325-344.</li>
<li>F. Cohen, <em><a href="/lib/afc13.html">A Short Course on Computer Viruses</a></em>, ASP Press, Pittsburgh, PA (1990).</li>
<li>S. Crocker and M. Pozzo, “A Proposal for a Veriﬁcation-Based Virus Filter,” <em>Proceedings of the 1989 IEEE Symposium on Security and Privacy</em> (May 1989) pp. 319-324.</li>
<li>D. Curry, “Improving the Security of Your UNIX System,” Technical Report ITSTD-721-FR-90-91, SRI International, Menlo Park, CA 94025 (Apr. 1990).</li>
<li>J. David, “Treating Viral Fever” <em>Computers and Security</em> 7(2) (Apr. 1988) pp. 255-258.</li>
<li>G. Davida, Y. Desmedt, and B. Matt, “Defending Systems Against Viruses through Cryptographic Authentication,” <em>Proceedings of the 1989 Symposium on Security and Privacy</em> (May 1989) pp. 312-318.</li>
<li>G. Davida and B. Matt, “UNIX Guardians: Delegating Security to the User,” <em>Proceedings of the UNIX Security Workshop</em> (Aug. 1988) pp. 14-23.</li>
<li>H. DeMaio, “Viruses – Management Issue,” <em>Computers and Security</em> 8(5) (Oct. 1989) pp. 381-388.</li>
<li>D. Denning, “An Intrusion-Detection Model,” <em>IEEE Transactions on Software Engineering</em> SE-13(2) (Feb. 1987) pp. 222-232.</li>
<li>P. Denning, “The Science of Computing: Computer Viruses,” <em>American Scientist</em> 76(3) (May 1988) pp. 236-238.</li>
<li>P. Denning, <em><a href="/lib/apd01.html">Computers Under Attack: Intruders, Worms, and Viruses</a></em>, Addison-Wesley Publishing Co., Reading, MA (1990),</li>
<li>A. Dewdney, <a href="/lib/mad02.html">“Computer Recreations: A Core War Bestiary of Viruses, Worms, and Other Threats to Computer Memories,”</a> <em>Scientiﬁc American</em> 252(3) (Mar. 1985) pp. 14-23.</li>
<li>A. Dewdney, <a href="/lib/mad03.html">“Computer Recreations,”</a> <em>Scientiﬁc American</em> 256(1) (Jan. 1987) pp. 14-20.</li>
<li><em>Trusted Computer System Evaluation Criteria</em>, DOD 5200.28-STD, Department of Defense (Dec. 1985).</li>
<li>D. Downs, J. Rub, K. Kung, and C. Jordan, “Issues in Discretionary Access Control,” <em>Proceedings of the 1984 IEEE Symposium on Security and Privacy</em>(Apr. 1984) pp. 208-218.</li>
<li>T. Duff, <a href="/lib/vtd01.html">“Experiences with Viruses on UNIX Systems,”</a> <em>Computing Systems</em> 2(2) (Spring 1989) pp. 155-172.</li>
<li>M. Eichin and J. Rochlis, “<a href="/lib/aem02.html">With Microscope and Tweezers: An Analysis of the Internet Virus of November 1988</a>,” <em>Proceedings of the 1989 IEEE Symposium on Security and Privacy</em> (Apr. 1989) pp. 326-343.</li>
<li>T. Eisenberg, D. Gries, J. Hartmanis, D. Holcomb, M. Lynn, and T. Santoro, <em>The Computer Worm: A Report to the Provost of Cornell University on an Investigation Conducted by the Commission of Preliminary Enquiry</em>, Cornell University, Ithaca, NY (Feb. 1989).</li>
<li>P. Elmer-DeWitt, <a href="/lib/med00.html">“Invasion of the Data Snatchers: A Virus Epidemic Strikes Terror in the Computer World,”</a> <em>Time</em> (Sep. 26, 1988) pp. 62-67.</li>
<li>V. Fåk, “Are We Vulnerable to a Virus Attack: A Report from Sweden,” <em>Computers and Security</em> 7(2) (Apr. 1988) pp. 151-155.</li>
<li>R. Farrow, <em>UNIX System Security</em>, Addison-Wesley Publishing Co., Reading, MA (1991).</li>
<li>P. Fites, P. Johnston, and M. Kratz, <em>The Computer Virus Crisis</em>, Van Nostrand Reinhold, New York City, NY (1988).</li>
<li>M. Gabriele, ““Smart” Terminals for Trusted Computer Systems,” <em>Ninth National Computer Security Conference Proceedings</em> (Sep. 1986) pp. 16-20.</li>
<li>S. Garﬁnkel and G. Spafford, <em>Practical UNIX Security</em>, O’Reilly and Associates (1991).</li>
<li>P. Garnett, “Selective Disassembly: A First Step Towards Developing a Virus Filter,” <em>Fourth Aerospace Computer Security Conference</em> (Dec. 1988) pp. 2-6.</li>
<li>M. Gemignani, <a href="/lib/mmg00.html">“Viruses and Criminal Law,”</a> <em>CACM</em> 32(6) (June 1989) pp. 669-671.</li>
<li>W. Gleissner, <a href="/lib/mwg02.html">“A Mathematical Theory for the Spread of Computer Viruses,”</a> <em>Computers and Security</em> 8(1) (Feb. 1989) pp. 35-41.</li>
<li>V. Gligor, C. Chandersekaran, R. Chapman, L. Dotterer, M. Hecht, W. Jiang, A. Johri, G. Luckenbaugh, and N. Vasudevan, “Design and Implementation of Secure Xenix,” <em>IEEE Transactions on Software Engineering</em> SE-13(2) (Feb. 1987) pp. 208-220.</li>
<li>F. Grampp and R. Morris, “UNIX Operating System Security,” <em>AT&amp;T Bell Laboratories Technical Journal</em> 63(8) (Oct. 1984) pp. 1649-1672.</li>
<li>J. Green and P. Sisson, “<a href="/lib/ajg00.html">The “Father Christmas” Worm</a>,” <em>Twelfth National Computer Security Conference Proceedings</em> (Oct. 1989) pp. 359-368.</li>
<li>K. Hafner, “Is Your Computer Secure?,” <em>Business Week</em> (Aug. 1, 1987) pp. 64-72.</li>
<li>J. Haigh and W. Young, “Extending the Non-Interference Version of MLS for SAT,” <em>Proceedings of the 1986 IEEE Symposium on Security and Privacy</em> (Apr. 1986) pp. 232-239.</li>
<li>H. Highland, “Random Bits and Bytes: Case History of a Virus Attack,” <em>Computers and Security</em> 7(1) (Feb. 1988) pp. 3-5.</li>
<li>H. Highland, “Random Bits and Bytes: Case History of a Virus Attack,” <em>Computers and Security</em> 7(1) (Feb. 1988) pp. 6-7.</li>
<li>H. Highland, “Random Bits and Bytes: Computer Viruses – A Post-Mortem,” <em>Computers and Security</em> 7(2) (Apr. 1988) pp. 117-127.</li>
<li>H. Highland, “The Brain Virus: Fact and Fantasy,” <em>Computers and Security</em> 7(4) (Aug. 1988) pp. 367-370.</li>
<li>H. Highland, “Random Bits and Bytes: Another Poor Password Disaster,” <em>Computers and Security</em> 9(1) (Feb. 1990) p. 10.</li>
<li>L. Hoffman, <em>Rogue Programs: Viruses, Worms, and Trojan Horses</em>, Van Nostrand Reinhold, New York City, NY (1990).</li>
<li>Homer, <em>The Odyssey</em>, Penguin Books, New York City, NY (1946).</li>
<li>H. Israel, “<a href="/lib/ahi00.html">Computer Viruses: Myth or Reality?</a>,” <em>Tenth National Computer Security Conference Proceedings</em> (Sep. 1987) pp. 226-230.</li>
<li>M. Joseph, “Towards the Elimination of the Effects of Malicious Logic: Fault Tolerance Approaches,” <em>Tenth National Computer Security Conference Proceedings</em> (Sep. 1987) pp. 238-244.</li>
<li>M. Joseph and A. Avižienis, “A Fault Tolerant Approach to Computer Viruses,” <em>Proceedings of the 1988 Symposium on Security and Privacy</em> (Apr. 1988) pp. 52-58.</li>
<li>J. Juni and R. Ponto, “Computer-Virus Infection of a Medical Diagnostic Computer,” <em>New England Journal of Medicine</em> 320(12) (Mar. 12, 1989) pp. 811-812.</li>
<li>P. Karger, “Limiting the Damage Potential of Discretionary Trojan Horses,” <em>Proceedings of the 1987 Symposium on Security and Privacy</em> (Apr. 1987) pp. 32-37.</li>
<li>P. Karger and R. Schell, “MULTICS Security Evaluation: Vulnerability Analysis,” Technical Report ESD-TR-74-193, Air Force Electronic Systems Division, Hanscom Air Force Base, MA (1974).</li>
<li>S. Kent and J. Linn, <em>Privacy Enhancement for Internet Electronic Mail: Part II -- Certiﬁcate-Based Key Management</em>, RFC 1114 (Aug. 1989).</li>
<li>B. Kernighan and T. Plauger, <em>The Elements of Programming Style</em>, McGraw-Hill Book Co., New York City, NY (1974).</li>
<li>J. Knight and N. Leveson, “An Experimental Evaluation of the Assumption of Independence in Multi-version Programming,” <em>IEEE Transactions on Software Engineering</em> SE-12(1) (Jan. 1986) pp. 96-109.</li>
<li>J. Knight and N. Leveson, “On N-version Programming,” <em>Software Engineering Notes</em> 15(1) (Jan. 1990) pp. 24-35.</li>
<li>S. Kramer, “Linus IV – An Experiment in Computer Security,” <em>Proceedings of the 1984 Symposium on Security and Privacy</em> (Apr. 1984) pp. 24-31.</li>
<li>S. Kurzban, “Viruses and Worms -- What Can You Do?,” <em>SIGSAC Review</em> 7(1) pp. 16-32.</li>
<li>N. Lai and T. Gray, “Strengthening Discretionary Access Controls to Inhibit Trojan Horses and Computer Viruses,” <em>1988 Summer USENIX Conference Proceedings</em> (June 1988) pp. 275-286.</li>
<li>B. Lampson, “Hints for Computer System Design,” <em>IEEE Software</em> 1(1) (Jan. 1984) pp. 11-28.</li>
<li>R. Levin, <em>Computer Virus Handbook</em>, McGraw-Hill Book Co., New York City, NY (1990).</li>
<li>T. Levin, S. Padilla, and C. Irvine, “A Formal Model for UNIX Setuid,” <em>Proceedings of the 1989 Symposium on Security and Privacy</em> (May 1989) pp. 73-83.</li>
<li>P. Lewis, “<a href="/lib/apl00.html">The Executive Computer: A Virus Carries Fatal Complications</a>,” <em>New York Times</em> (June 26, 1988) p. C-11.</li>
<li>J. Linn, <em>Privacy Enhancement for Internet Electronic Mail: Part III – Algorithms, Modes, and Identiﬁers</em>, RFC-1115 (Aug. 1989).</li>
<li>S. Lipner, “Non-Discretionary Controls for Commercial Applications,” <em>Proceedings of the 1982 Symposium on Security and Privacy</em> (Apr. 1982) pp. 2-10.</li>
<li>T. Lunt and R. Jagannathan, “A Prototype Real-Time Intrusion-Detection Expert System,” <em>Proceedings of the 1988 Symposium on Security and Privacy</em> (Apr. 1988) pp. 59-66.</li>
<li>J. McAfee, “4096 and 1260 Viruses (PC),” <em>Virus-L Digest</em> 3(27) (Jan. 31, 1990), submitted by A. Roberts.</li>
<li>J. McAfee and C. Haynes, <em>Computer Viruses, Worms, Data Diddlers, Killer Programs, and Other Threats to Your System</em>, St. Martin’s Press, New York City, NY (1989).</li>
<li>J. Markoff, “‘Virus’ in Military Computers Disrupts Systems Nationwide,” <em>New York Times</em> (Nov. 4, 1988) p. A-1.</li>
<li>J. Markoff, “Top-Secret, And Vulnerable,” <em>New York Times</em> (Apr. 25, 1988) p. A-1.</li>
<li>J. Markoff, “Student Says Error in Experiment Jammed a Network of Computers,” <em>New York Times</em> (Jan. 19, 1990) p. A-19.</li>
<li>V. McLellan, “<a href="/lib/avm00.html">Computer Systems Under Siege</a>,” <em>New York Times</em> (Jan. 31, 1989) p. C-3.</li>
<li>R. Merkle, “A Fast Software One Way Hash Function,” <em>unpublished</em>.</li>
<li>G. Miller, S. Sutton, M. Matthews, J. Yip, and T. Thomas, “Integrity Mechanisms in a Secure UNIX: GOULD UTX/32S,” <em>AIAA/ASIS/DODCI Second Aerospace Computer Security Conference: A Collection of Technical Papers</em> (Dec. 1986) pp. 19-26.</li>
<li>W. Murray, “<a href="/lib/awm00.html">The Application of Epidemiology to Computer Viruses</a>,” <em>Computers and Security</em> 7(1) (Feb. 1988) pp. 139-150.</li>
<li>P. Neumann and D. Parker, “A Summary of Computer Misuse Techniques,” <em>Twelfth National Computer Security Conference Proceedings</em> (Oct. 1989) pp. 396-407.</li>
<li>A. Norman, <em>Computer Insecurity</em>, Chapman and Hall, New York City, NY (1983).</li>
<li>J. Page, “An Assured Pipeline Integrity Scheme for Virus Protection,” <em>Twelfth National Computer Security Conference Proceedings</em> (Oct. 1989) pp. 369-377.</li>
<li>D. Parker, <em>Crime by Computer</em>, Charles Scribner’s Sons, New York City, NY (1976).</li>
<li>J. Picciotto, “The Design of an Effective Auditing Subsystem,” <em>Proceedings of the 1987 Symposium on Security and Privacy</em> (Apr. 1987) pp. 13-22.</li>
<li>G. Popek and B. Walker, <em>The LOCUS Distributed System Architecture</em>, The MIT Press, Cambridge, MA (1985).</li>
<li>M. Pozzo and T. Gray, “A Model for the Containment of Computer Viruses,” <em>AIAA/ASIS/DODCI Second Aerospace Computer Security Conference</em> (Dec. 1986) pp. 11-18.</li>
<li>M. Pozzo and T. Gray, “<a href="/lib/atg00.html">An Approach to Containing Computer Viruses</a>,” <em>Computers and Security</em> 6(4) (Aug. 1987) pp. 321-331.</li>
<li>B. Randell, P. Lee, and P. Treleaven, “Reliability Issues in Computing System Design,” <em>Computing Surveys</em> 10(2) (June 1978) pp. 167-196.</li>
<li>D. Ritchie, “<a href="/lib/mdr00.html">Joy of Reproduction</a>,” USENET newsgroup <em>net.lang.c</em> (Nov. 4, 1982).</li>
<li>R. Roberts, <em><a href="/lib/arr00.html">Computer Viruses</a></em>, Compute! Books, Greensboro, NC (1988).</li>
<li>J. Rochlis and M. Eichin, “With Microscope and Tweezers: The Worm from MIT’s Perspective,” <em>CACM</em> 32(6) (June 1989) pp. 689-698.</li>
<li>J. Saltzer and M. Schroeder, “The Protection of Information in Computer Systems,” <em>Proceedings of the IEEE</em> 63(9) (Sep. 1975) pp. 1278-1308.</li>
<li>P. Samuelson, <a href="/lib/mps00.html">“Can Hackers Be Sued for Damages Caused by Computer Viruses?,”</a> CACM 32(6) (June 1989) pp. 666-669.</li>
<li>O. Saydjari, J. Beckman, and J. Leaman, “Locking Computers Securely,” <em>Tenth National Computer Security Conference Proceedings</em> (Sep. 1987) pp. 129-141.</li>
<li>O. Saydjari, J. Beckman, and J. Leaman, “LOCK Trek: Navigating Uncharted Space,” <em>Proceedings of the 1989 Symposium on Security and Privacy</em> (May 1989) pp. 167-175.</li>
<li>R. Schatz, “New ‘Virus’ Infects NASA Macintoshes,” <em>Washington Post</em> (Apr. 18, 1988), Washington Business section, p. 25.</li>
<li>J. Schoch and J. Hupp, <a href="/lib/ajm01.html">“The “Worm” Programs – Early Experiences with a Distributed Computation,”</a> <em>CACM</em> 25(3) (Mar. 1982) pp. 172-180.</li>
<li>P. Scott, “Re: Faking Internet Mail [Re: RISKS-8.27],” <em>Forum on the Risks to the Public in Computers and Related Systems</em> 8(28) (Feb. 19, 1989).</li>
<li>D. Seeley, “Password Cracking: A Game of Wits,” <em>CACM</em> 32(6) (June 1989) pp. 700-703.</li>
<li>D. Seeley, <a href="/lib/ase01.html">“A Tour of the Worm,”</a> <em>Proceedings of USENIX Winter ‘89</em> (Jan. 1989) pp. 287-304.</li>
<li>P. Singer, “Trying to Put a Brake on Computer Theft,” <em>New York Times</em> (Mar. 2, 1986) p. WC-17.</li>
<li>K. Smith, “Tales of the Damned,” <em>UNIX Review</em> 6(2) (Feb. 1988) pp. 45-50.</li>
<li>T. Smith, “User Deﬁnable Domains as a Mechanism for Implementing the Least Privilege Principle,” <em>Ninth National Computer Security Conference Proceedings</em> (Sep. 1986) pp. 143-148.</li>
<li>E. Spafford, <a href="/lib/aes01.html">“Crisis and Aftermath,”</a> <em>CACM</em> 32(6) (June 1989) pp. 678-687.</li>
<li>E. Spafford, “The Internet Worm Program: An Analysis,” <em>ACM Computer Communications Review</em> 19(1) (Jan. 1989).</li>
<li>E. Spafford, K. Heaphy, and D. Ferbrache, <em>Computer Viruses: Dealing with Electronic Vandalism and Programmed Threats</em>, ADAPSO, Arlington, VA (1989).</li>
<li>C. Stoll, “<a href="/lib/mcs01.html">An Epidemiology of Viruses &amp; Network Worms</a>,” <em>Twelfth National Computer Security Conference Proceedings</em> (Oct. 1989) pp. 369-377.</li>
<li>H. Teng, K. Chen, and S. Lu, “Adaptive Real-Time Anomaly Detection Using Inductively Generated Sequential Patterns,” <em>Proceedings of the 1990 Symposium on Research in Security and Privacy</em> (May 1990) pp. 278-284.</li>
<li>K. Thompson, <a href="/lib/mkt00.html">“Reﬂections on Trusting Trust,”</a> Communications of the ACM 27(8) (Aug. 1984) pp. 761-763.</li>
<li>M. Todd, “Man Catches Computer Virus!,” <em>Weekly World News</em> p. 29 (June 18, 1991).</li>
<li>United States Comptroller General, “Computer-Related Crimes in Federal Programs,” Report FGMSD-76-27, United States Government Printing Ofﬁce, Washington, D. C. (Apr. 27, 1976).</li>
<li>United States Congress Ofﬁce of Technology Assessment, <em>Defending Secrets, Sharing Data: New Locks and Keys for Electronic Information</em>, Report OTA-CIT-310, United States Government Printing Ofﬁce, Washington, D. C. (Oct. 1987).</li>
<li>Virgil, <em>The Æneid</em>, Random House, New York City, NY (1983).</li>
<li>C. von Rospach, “How to Post a Fake,” <em>Forum on the Risks to the Public in Computers and Related Systems</em> 4(75) (Apr. 20, 1987).</li>
<li>V. Voydock and S. Kent, “Security Mechanisms in High-Level Network Protocols,” <em>Computing Surveys</em> 15(2) (June 1983) pp. 135-171.</li>
<li>S. Wiseman, “Preventing Viruses in Computer Systems,” <em>Computers and Security</em> 8(5) (Aug. 1989) pp. 427-432.</li>
<li>I. Witten, <a href="/lib/aiw00.html">“Computer (in)security: Inﬁltrating Open Systems,”</a> <em>Abacus</em> 4(4) (1987) pp. 7-25.</li>
<li>P. Wood and S. Kochan, <em>UNIX™ System Security</em>, Hayden Books, Indianapolis, IN (1985).</li>
<li>C. Young, “Taxonomy of Computer Virus Defense Mechanisms,” <em>Tenth National Computer Security Conference Proceedings</em> (Sep. 1987) pp. 220-225.</li>
</ol>
<h2><a name="ca"></a>Sidebar 1 – The First Trojan Horse</h2>
<p><em>There are many contradictory versions of this story; it appears only brieﬂy in The Odyssey ([68], Book VIII), but later writers elaborated it considerably. Aeneas, a Trojan survivor of the sacking of the city, told the following version to Queen Dido of Carthage during his wanderings that ended with the founding of Rome ([131], Book II).</em></p>
<p>After many years of besieging Troy and failing to take the city, the Greeks, on the advice of Athene, their patron goddess, built a large wooden horse in which many Greek soldiers hid. The horse was inscribed with a prayer to Athene to grant the Greeks safe passage home, and then the Greek army left.</p>
<p>The next morning, the Trojans discovered the siege had been lifted and went to examine the wooden horse. One of the elders, Thymoetes, noticed the inscription, and urged the horse be brought into the city and placed in Athene’s temple. Others counseled that the horse must be destroyed; Laocoon, a priest of Apollo, threw a spear against the horse’s belly as he cried that he did not trust Greeks bearing gifts.</p>
<p>Meanwhile, shepherds allied with the Trojans brought over a Greek soldier named Sinon. Sinon explained that the Greeks had desecrated Apollo’s shrine and killed a virgin attendant in a raid, so to appease Apollo they had to sacriﬁce one of their men. Sinon was chosen. He promptly ﬂed and was abandoned when the Greeks left for home. As for the horse, Sinon claimed that one night Odysseus and Diomede desecrated Athene’s shrine, turning their protecting goddess against them. Calchas, the Greeks’ priest, advised that the horse must be built to appease the goddess before they could leave; and the horse was made so big to keep the Trojans from moving it into their city, for if they did their triumph over the Greeks would be assured.</p>
<p>At that moment, two sea serpents slithered out of the waters and crushed Laocoon and his sons to death. Believing this to be retribution for his profaning an offering to Athene, the Trojans immediately breached the walls of the city and pulled the horse inside.</p>
<p>That night, as the Trojans celebrated, they did not notice Sinon slip out to the horse and open a trap door through which the Greek soldiers emerged, nor did they see the Greeks opening the gates to the city. The Greek forces had by this time returned, and they sacked the city. Aeneas and his companions alone escaped.</p>
<h2><a name="cb"></a>Sidebar 2 – Anatomy of a Virus</h2>
<p>This pseudocode fragment shows how a very simple computer virus works:</p>
<pre class="source">
beginvirus:
	if spread-condition then begin
		for some set of target files do begin
			if target is not infected then begin
				determine where to place virus instructions
				copy instructions from beginvirus to endvirus into target
				alter target to execute added instructions
			end;
		end;
	end;
	perform some action
	goto beginning of infected program
endvirus:
</pre>
<p>First, the virus determines if it is to spread; if so, it locates a set of target ﬁles it is to infect, and copies itself into a convenient location within the target ﬁle. It then alters portions of the target to ensure the inserted code will be executed at some time. For example, the virus may append itself just beyond the end of the instruction space and then adjust the entry points used by the loader so that the added instructions will execute when the target program is next run. This is the <em>infection phase</em> It then performs some other action (the <em>execution phase</em>). Finally, it returns control to the program currently being run. Note that the execution phase can be null and the instructions still constitute a virus; but if the infection phase is missing, the instructions are <em>not</em> a virus.</p>
<p>The Lehigh virus [62] had as a <em>spread-condition</em> that “there is an uninfected boot ﬁle on the disk;” the <em>set of target ﬁles</em> was “the uninfected boot ﬁle,” and <em>perform some action</em> was to increment a counter and test to see if the counter had reached 4; if so, it would erase the disk.</p>
<h2><a name="cc"></a>Sidebar 3 – A Starting Point for Suggested Guidelines for UNIX-based Systems</h2>
<p>This list of suggestions, intended as a starting point for a basic, “vanilla” UNIX-based computer system, may help prevent the introduction of malicious logic, like computer viruses, into the computer system, and also lessen the chances of accidentally invoking programs with that type of logic. Attackers can render these methods ineffective because the weaknesses they seek to patch are fundamental to the design and use of the computer system, and anything effective would require changing the system more than is practical. Still, following these suggestions may help.</p>
<p>More details on UNIX security in general may be found in [33], [50], [53], and [136].</p>
<ol>
<li>Set the environment variables (such as <strong>PATH</strong>) to access trusted programs before accessing untrusted programs of the same name.
<p>The UNIX shell checks the value of the variable <strong>PATH</strong> for a list of directories to check for programs. The system administrator had put the current working directory before the system directories in the example in §6.1., Hence the user’s directory listing program, not the system one, was executed.</p></li>
<li>Do not execute a program obtained from an untrusted source without checking the source code thoroughly.
<p>This rule presumes that the underlying computing base (compiler, loader, operating system, etc.) are all uncorrupted; if this assumption is false, malicious logic may be inserted during compilation, linking, or execution. An obvious corollary is to test all such software in an environment with very limited privileges before installing it, and <em>never</em> to test the program where it can access critical or irreplaceable ﬁles, or as a highly-privileged user.</p></li>
<li>Design and implement some auditing scheme to ensure that ﬁles’ access control permissions match the settings speciﬁed in an access control plan.
<p>This requires ﬁrst, that some security policy designating who has access to what ﬁles and how be created; and second, that some enforcement mechanism be implemented. Note the <em>caveat</em>: if the audit log created by that mechanism, or the mechanism itself, can be tampered with, the introduction of malicious logic into the system can be done undetectably. However, depending on the security mechanisms implementing the auditing and the access to the log, this may require some sophistication. (Or, it may not.)</p></li>
<li>Check the integrity of system ﬁles to ensure they have not changed unexpectedly.
<p>This is really a corollary to the previous rule. Note that the checksums computed at installation must be protected, since an attacker could change a ﬁle, then compute its new checksum and replace the stored checksum with it. Again, this requires that the underlying system be trusted to provide such protection to the checksum program, the stored checksums, and the audit program comparing the two.</p></li>
<li>Backups should be made regularly and kept as long as reasonable.
<p>Typically, sites make both daily and weekly incremental backups (which save all ﬁles that have changed since the last incremental backup of the same period); then once a month they simply make a copy of all ﬁle systems. Enough of each kind is saved to be able to restore the system to its current state. Notice that if restoring to eliminate a malicious program, the restored version of the program should also be <em>thoroughly</em> checked.</p></li>
<li>Discuss with your systems staff and users the reasons for, and effects of, any actions taken for security reasons.
<p>The system staff should cultivate good relations with the users and vendors, should be certain to explain the reasons for all security policies, and should assist users whenever possible in providing a pleasant and secure working environment, acting as an intermediary between them and the vendors if need be. Users and staff should know what constitutes a breach of security, and there should be a well-designed set of procedures for handling breaches. Thinking through the best procedures for a particular installation carefully, putting them into place tactfully, and explaining them fully, will do far more to prevent security problems than any quick action.</p></li>
<li>All installations should keep the original distribution of the computer system in a safe place, and make and protect backups as well.
<p>If malicious programs are determined to be rampant on the system, the administrators should reload the original compilation and installation software from the distribution medium and recompile and regenerate all system ﬁles after checking all sources thoroughly. This assumes that the (distributed) compilation and installation software is not infected and the program loading that software does not infect it. As always, the elements of trust are present here.</p></li>
<li>When reading backups, mount the backup medium in such a way that it cannot be changed or erased.
<p>The reason is explained in the text. Note this means preventing modiﬁcation access <em>by the hardware</em>, for example by removing the write ring from a tape. If the prevention mechanism is done in software, it can be infected and/or disabled by a malicious program. Here, the element of trust is in the hardware mechanism working correctly.</p></li>
<li>Access privileged accounts only when necessary, and then for as brief a time as possible.
<p>Should someone using a privileged account accidentally execute a program containing a computer virus, the virus will spread throughout the system rapidly. This is less likely to happen if those accounts are used only when necessary; even so, a window of vulnerability still exists. Computers designed with security in mind typically limit the power of privileged accounts, in some cases very drastically.</p></li>
<li>Write as few privileged programs as possible.
<p>The more programs that can cross protection domain boundaries while executing, the more potential targets for the addition of malicious logic exist. This suggestion essentially recommends minimizing the number of programs that can be modiﬁed to provide an attacker with entry to the privileged state.</p></li>
<li>Do not use a smart terminal to access a privileged account.</li>
<li>If a smart terminal must be used to access a privileged account, never allow an inter-terminal communications program to write to the terminal, never read electronic mail from that terminal, and do not look at ﬁles the contents of which are unknown or suspect.
<p>Note that the second version is much weaker, because a malicious program could tamper with an executable program and cause it to display the control sequences to produce the requisite commands from the terminal. The privileged user executing such a command springs the trap. Any ﬁle the malicious program could write to can be similarly booby-trapped.</p></li>
<li>Prevent users from accessing devices and memory directly.
<p>If memory and devices are objects addressable by the user, the access control plan described earlier should include these objects and prevent direct access to them. Speciﬁcally, the device and memory ﬁles on UNIX systems should <em>never</em> have any <em>world</em> permissions set; this gives users direct access to memory and to the raw device, and allows them to bypass the UNIX access control mechanisms.</p></li>
</ol>
<h2><a name="cd"></a>Sidebar 4 – Forums that Discuss Viruses</h2>
<p>The VIRUS-L mailing list, moderated by Kenneth R. van Wyk, is a forum for discussing all aspects of computer viruses, especially existing computer viruses and countermeasures as well as theory. To subscribe, send an electronic mail message containing only the line</p>
<pre class="source">SUB VIRUS-L your name</pre>
<p>to <a class="__cf_email__" href="/cdn-cgi/l/email-protection" data-cfemail="e8a4a1bbbcbbadbabea8a4ada0a1a1aaa5d9c6aaa1bca6adbcc6">[email&#160;protected]</a><script data-cfhash='f9e31' type="text/rocketscript">/* <![CDATA[ */!function(t,e,r,n,c,a,p){try{t=document.currentScript||function(){for(t=document.getElementsByTagName('script'),e=t.length;e--;)if(t[e].getAttribute('data-cfhash'))return t[e]}();if(t&&(c=t.previousSibling)){p=t.parentNode;if(a=c.getAttribute('data-cfemail')){for(e='',r='0x'+a.substr(0,2)|0,n=2;a.length-n;n+=2)e+='%'+('0'+('0x'+a.substr(n,2)^r).toString(16)).slice(-2);p.replaceChild(document.createTextNode(decodeURIComponent(e)),c)}p.removeChild(t)}}catch(u){}}()/* ]]> */</script> Back issues of the digest are available by anonymous ftp from IBM1.CC.LEHIGH.EDU or cert.sei.cmu.edu; users not on the internet may send to the above address an electronic mail message containing only the line</p>
<pre class="source">GET VIRUS-L LOGyymmx</pre>
<p>where yy is the last two digits of the year, mm the number of the month, and x a letter indicating the number of the week in the month. For example, LOG8901B refers to the digests issued in the second week of January, 1989.</p>
<p>The mailing list VALERT-L is used <em>only</em> to announce viruses; any discussion is relegated to VIRUS-L. To subscribe, send an electronic mail message containing only the line</p>
<pre class="source">SUB VALERT-L your name</pre>
<p>to the above address. Messages sent to VALERT-L appear in the next VIRUS-L digest as well.</p>
<p>Peter Neumann of SRI International moderates the Forum on Risks to the Public in Computers and Related Systems, or RISKS, list. This mailing list focuses on the risks involved in computer technology, and has discussed implications of viruses, although with a thrust different than the VIRUS-L mailing list. To subscribe, if on the Internet, send an electronic mail message to <a class="__cf_email__" href="/cdn-cgi/l/email-protection" data-cfemail="316378627a621c435440445442457172627d1f6263781f727e7c">[email&#160;protected]</a><script data-cfhash='f9e31' type="text/rocketscript">/* <![CDATA[ */!function(t,e,r,n,c,a,p){try{t=document.currentScript||function(){for(t=document.getElementsByTagName('script'),e=t.length;e--;)if(t[e].getAttribute('data-cfhash'))return t[e]}();if(t&&(c=t.previousSibling)){p=t.parentNode;if(a=c.getAttribute('data-cfemail')){for(e='',r='0x'+a.substr(0,2)|0,n=2;a.length-n;n+=2)e+='%'+('0'+('0x'+a.substr(n,2)^r).toString(16)).slice(-2);p.replaceChild(document.createTextNode(decodeURIComponent(e)),c)}p.removeChild(t)}}catch(u){}}()/* ]]> */</script>; if on BITNET, send an electronic mail message containing only the line</p>
<pre class="source">SUBSCRIBE MD4H your name</pre>
<p>to <a class="__cf_email__" href="/cdn-cgi/l/email-protection" data-cfemail="dc90958f888f998e8a9c9f91899f9f8a919df29e9588929988">[email&#160;protected]</a><script data-cfhash='f9e31' type="text/rocketscript">/* <![CDATA[ */!function(t,e,r,n,c,a,p){try{t=document.currentScript||function(){for(t=document.getElementsByTagName('script'),e=t.length;e--;)if(t[e].getAttribute('data-cfhash'))return t[e]}();if(t&&(c=t.previousSibling)){p=t.parentNode;if(a=c.getAttribute('data-cfemail')){for(e='',r='0x'+a.substr(0,2)|0,n=2;a.length-n;n+=2)e+='%'+('0'+('0x'+a.substr(n,2)^r).toString(16)).slice(-2);p.replaceChild(document.createTextNode(decodeURIComponent(e)),c)}p.removeChild(t)}}catch(u){}}()/* ]]> */</script>, or</p>
<pre class="source">SUBSCRIBE RISKS your name</pre>
<p>to <a class="__cf_email__" href="/cdn-cgi/l/email-protection" data-cfemail="5814110b0c0b1d0a0e180d1f19761a110c161d0c">[email&#160;protected]</a><script data-cfhash='f9e31' type="text/rocketscript">/* <![CDATA[ */!function(t,e,r,n,c,a,p){try{t=document.currentScript||function(){for(t=document.getElementsByTagName('script'),e=t.length;e--;)if(t[e].getAttribute('data-cfhash'))return t[e]}();if(t&&(c=t.previousSibling)){p=t.parentNode;if(a=c.getAttribute('data-cfemail')){for(e='',r='0x'+a.substr(0,2)|0,n=2;a.length-n;n+=2)e+='%'+('0'+('0x'+a.substr(n,2)^r).toString(16)).slice(-2);p.replaceChild(document.createTextNode(decodeURIComponent(e)),c)}p.removeChild(t)}}catch(u){}}()/* ]]> */</script>, <a class="__cf_email__" href="/cdn-cgi/l/email-protection" data-cfemail="92dedbc1c6c1d7c0c4d2c7d0c4dfbcd0dbc6dcd7c6">[email&#160;protected]</a><script data-cfhash='f9e31' type="text/rocketscript">/* <![CDATA[ */!function(t,e,r,n,c,a,p){try{t=document.currentScript||function(){for(t=document.getElementsByTagName('script'),e=t.length;e--;)if(t[e].getAttribute('data-cfhash'))return t[e]}();if(t&&(c=t.previousSibling)){p=t.parentNode;if(a=c.getAttribute('data-cfemail')){for(e='',r='0x'+a.substr(0,2)|0,n=2;a.length-n;n+=2)e+='%'+('0'+('0x'+a.substr(n,2)^r).toString(16)).slice(-2);p.replaceChild(document.createTextNode(decodeURIComponent(e)),c)}p.removeChild(t)}}catch(u){}}()/* ]]> */</script>, or <a class="__cf_email__" href="/cdn-cgi/l/email-protection" data-cfemail="c08c899394938592968086898e88959483ee8289948e8594ee">[email&#160;protected]</a><script data-cfhash='f9e31' type="text/rocketscript">/* <![CDATA[ */!function(t,e,r,n,c,a,p){try{t=document.currentScript||function(){for(t=document.getElementsByTagName('script'),e=t.length;e--;)if(t[e].getAttribute('data-cfhash'))return t[e]}();if(t&&(c=t.previousSibling)){p=t.parentNode;if(a=c.getAttribute('data-cfemail')){for(e='',r='0x'+a.substr(0,2)|0,n=2;a.length-n;n+=2)e+='%'+('0'+('0x'+a.substr(n,2)^r).toString(16)).slice(-2);p.replaceChild(document.createTextNode(decodeURIComponent(e)),c)}p.removeChild(t)}}catch(u){}}()/* ]]> */</script> Back issues of the digest are available by anonymous ftp from crvax.sri.com in the directory “RISKS:” and are named RISKS-v.nn where v is the volume and nn the number within the volume.</p>
<hr size="1"/>
<p><a name="f1" href="#b1">1.</a> UNIX is a registered trademark of AT&amp;T Bell Laboratories.</p>
<p><a name="f2" href="#b2">2.</a> VAX and VMS are registered trademarks of Digital Equipment Corporation.</p>
<p><a name="f3" href="#b3">3.</a> D. Edwards ﬁrst referred to this type of program as a “Trojan horse” in [4]</p>
<p><a name="f4" href="#b4">4.</a> Originally, a worm was simply a distributed computation [115]; it is now most often used in the above sense.</p>
<p><a name="f5" href="#b5">5.</a> TOPS-20 is a registered trademark of Digital Equipment Corporation.</p>
<p><a name="f6" href="#b6">6.</a> VM/370 is a registered trademark of IBM.</p>
<p><a name="f7" href="#b7">7.</a> We use the conventional terminology of calling this program a “computer worm” because its dominant method of propagation was from computer system to computer system. Others, notably [46], have labelled it a “computer virus” using a taxonomy more ﬁrmly grounded in biology than the conventional one.</p>
<p><a name="f8" href="#b8">8.</a> Reading private ﬁles to obtain information (such as user names and passwords) that can then be used to break into other systems, or other parts of the system on which the information is found.</p>
<p><a name="f9" href="#b9">9.</a> Macintosh is a Registered Trademark of Apple Computer</p>
<p><a name="f10" href="#b10">10.</a> Cohen tantalizingly claims that one has been found, but reports no other details [27]. Suppression of details (or, more commonly, the existence) of attacks, virus or otherwise, is common; it is estimated that victims report only 10% to 35% of computer crimes in general [119][129], in part to prevent embarrassment or loss of public conﬁdence in the company, or to avoid the expense of gathering sufﬁcient evidence to prosecute the offender [101].</p>
<p><a name="f11" href="#b11">11.</a> It is worth noting that the author of the Internet worm stated that the worm disabled machines due to a programming error [93].</p>
[<a style="" href="/lib/?lang=EN&amp;index=AV#amb01">Back to index</a>] [<a href="/lib/amb01.html#disqus_thread">Comments</a>]<br/> <div id="disqus_thread"></div>
<script type="text/rocketscript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'vxheaven'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
<div><small>By accessing, viewing, downloading or otherwise using this content you agree to be bound by the <a href="/agreement.php">Terms of Use</a>!</small> <small>vxheaven.org aka vx.netlux.org</small></div>
<div style="margin-top: 2px; float: left;" class="adsapeu">
<script type="text/rocketscript">
<!--
var _acic={dataProvider:10};(function(){var e=document.createElement("script");e.type="text/javascript";e.async=true;e.src="//www.acint.net/aci.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)})()
//-->
</script>
</div>
<script data-rocketsrc="http://www.google-analytics.com/urchin.js" type="text/rocketscript"></script><script type="text/rocketscript">try { _uacct = "UA-590608-1"; urchinTracker(); } catch(err) {}</script>
<div style="display: none;"><a href="/lib/index.php?lang=de&amp;id=amb01">de</a><a href="/lib/index.php?lang=en&amp;id=amb01">en</a><a href="/lib/index.php?lang=es&amp;id=amb01">es</a><a href="/lib/index.php?lang=it&amp;id=amb01">it</a><a href="/lib/index.php?lang=fr&amp;id=amb01">fr</a><a href="/lib/index.php?lang=pl&amp;id=amb01">pl</a><a href="/lib/index.php?lang=ru&amp;id=amb01">ru</a><a href="/lib/index.php?lang=ua&amp;id=amb01">ua</a></div>
</body>
</html>
