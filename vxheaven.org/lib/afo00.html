<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>Stephanie Forrest, Steven Hofmeyr, Anil Somayaji, Thomas Longstaff 'A Sense of Self for Unix Processes' (VX heaven)</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8"/>
<meta name="Author" content="Stephanie Forrest, Steven Hofmeyr, Anil Somayaji, Thomas Longstaff"/>
<meta name="KeyWords" lang="en" content="computer virus, virus, virii,vx, компьютерные вирусы, вирус, вири, Forrest, Stephanie; Hofmeyr, Steven; Somayaji, Anil; Longstaff, Thomas,Sense of Self for Unix Processes, sendmail, detection, computer, immune, cert, intrusion, deﬁnition, database, systems, attack, security, open, normal, message, position"/>
<meta name="Description" content="A method for anomaly detection is introduced in which “normal” is deﬁned by short-range correlations in a process’ system calls. Initial experiments suggest that the deﬁnition is stable during normal behavior for standard UNIX programs. Further, it is able to detect several common intrusions involving sendmail and lpr. This work is part of a research program aimed at building computer security systems that incorporate the mechanisms and algorithms used by natural immune systems."/>
<script type="text/javascript">
//<![CDATA[
try{if (!window.CloudFlare) {var CloudFlare=[{verbose:0,p:0,byc:0,owlid:"cf",bag2:1,mirage2:0,oracle:0,paths:{cloudflare:"/cdn-cgi/nexp/dok3v=1613a3a185/"},atok:"047a5bcbf67431883fc9ed25fba33612",petok:"ea452039dc4c5d2318cb3826c648a302130b4512-1498757121-1800",zone:"vxheaven.org",rocket:"a",apps:{}}];document.write('<script type="text/javascript" src="//ajax.cloudflare.com/cdn-cgi/nexp/dok3v=85b614c0f6/cloudflare.min.js"><'+'\/script>');}}catch(e){};
//]]>
</script>
<link rel="icon" href="/favicon.ico" type="image/x-icon"/>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"/>
<link rel="stylesheet" type="text/css" href="/style.css"/><link rel="canonical" href="http://vxheaven.org/lib/afo00.html"/>
<script type="text/rocketscript" data-rocketsrc="https://apis.google.com/js/plusone.js">{"parsetags": "explicit"}</script>
</head>
<body bgcolor="#dbc8a0" text="#302000" link="#225599" vlink="#113366">
<div class="s1">
<div style="float:right;"><a href="/lib/index.php?tbs=1"><img src="/img/max.gif" alt="Maximize"/></a></div> <form id="lf" style="margin: 0; float: right;" method="get" action="/index.php"><input type="hidden" name="action" value="set"/><select name="lang" onchange="javascript:document.getElementById('lf').submit();"><option value="ru">Русский</option><option selected="selected" value="en">English</option><option value="ua">Українська</option><option value="de">Deutsch</option><option value="es">Español</option><option value="fr">Fran&ccedil;ais</option><option value="it">Italiano</option><option value="pl">Polski</option></select></form>
<div style="float: right;"><div id="plusone"></div></div>
<script type="text/rocketscript">gapi.plusone.render("plusone", {"size":"small","count":"true"});</script>
<div style="float: right;" class="addthis_toolbox addthis_default_style">
<script type="text/rocketscript">var addthis_config = { ui_click: true }</script>
<a style="text-decoration: none; font-size: 10pt;" href="/?action=addthis" class="addthis_button_compact">Bookmark</a>
<script type="text/rocketscript" data-rocketsrc="http://s7.addthis.com/js/250/addthis_widget.js#username=herm1t"></script>
</div>
<div style="float: right;">
<script type="text/rocketscript" data-rocketsrc="http://www.google.com/cse/brand?form=cse-search-box&amp;lang=en"></script>
<form action="/search.php" id="cse-search-box">
<input type="hidden" name="cx" value="002577580816726040001:z9_irkorydo"/>
<input type="hidden" name="cof" value="FORID:10"/>
<input type="hidden" name="ie" value="UTF-8"/>
<input type="text" name="q" size="12" value=" "/>
<input type="submit" name="sa" value="Search"/>
</form>
</div><h1><a href="/" style="text-decoration: none; color: #000000;">VX Heaven</a></h1>
<span class="nav"><a href="/lib/">Library</a> <a href="/vl.php">Collection</a> <a href="/src.php">Sources</a> <a href="/vx.php?id=eidx">Engines</a> <a href="/vx.php?id=tidx">Constructors</a> <a href="/vx.php?id=sidx">Simulators</a> <a href="/vx.php?id=uidx">Utilities</a> <a href="/links.php">Links</a> <a href="/donate.php" style="color: #706020" id="donate">Donate</a> <a href="/forum" style="text-decoration: underline;">Forum</a> </span><br clear="all"/>
</div>
<div class="s2"><h1>A Sense of Self for Unix Processes</h1><p><a href="/lib/?lang=en&amp;author=Forrest%2C%20Stephanie">Stephanie Forrest</a>, <a href="/lib/?lang=en&amp;author=Hofmeyr%2C%20Steven">Steven Hofmeyr</a>, <a href="/lib/?lang=en&amp;author=Somayaji%2C%20Anil">Anil Somayaji</a>, <a href="/lib/?lang=en&amp;author=Longstaff%2C%20Thomas">Thomas Longstaff</a><br/> <em>In Proceedings of the 1996 IEEE Symposium on Security and Privacy, IEEE Computer Society Press, Los Alamitos, CA, pp. 120–128</em><br/> <em> 1996</em></p><script type="text/rocketscript">var disqus_url = 'http://vxheaven.org/lib/afo00.html';</script><div class="ci"><a href="/lib/?ci=afo00">4</a></div><img src="/img/pdf.gif" alt="PDF"/><a href="/lib/pdf/A%20Sense%20of%20Self%20for%20Unix%20Processes.pdf">Download</a> PDF (68.12Kb) (You need to be registered on <a href="/forum">forum</a>)<br/>[<a style="" href="/lib/?lang=EN&amp;index=IM#afo00">Back to index</a>] [<a href="/lib/afo00.html#disqus_thread">Comments</a>]<br/> <form method="post" action="">
<img src="/img/cache/0b9fd596a90421f9f1f68a9760275737.gif" alt="\text{T_EX size}" valign="middle"/>
<select name="TeX_size"><option value="-2">-2</option><option value="-1">-1</option><option value="0" selected="selected">0</option><option value="1">1</option><option value="2">2</option><option value="3">3</option><option value="4">4</option><option value="5">5</option> </select>
<input type="submit" value="Scale"/>
</form>
<address> 
<p>Stephanie Forrest, Steven A. Hofmeyr, Anil Somayaji<br/>
Dept. of Computer Science University of New Mexico<br/>
Albuquerque, NM 87131-1386 {forrest,steveah,<a class="__cf_email__" href="/cdn-cgi/l/email-protection" data-cfemail="55263a3834281536267b203b387b303120">[email&#160;protected]</a><script data-cfhash='f9e31' type="text/rocketscript">/* <![CDATA[ */!function(t,e,r,n,c,a,p){try{t=document.currentScript||function(){for(t=document.getElementsByTagName('script'),e=t.length;e--;)if(t[e].getAttribute('data-cfhash'))return t[e]}();if(t&&(c=t.previousSibling)){p=t.parentNode;if(a=c.getAttribute('data-cfemail')){for(e='',r='0x'+a.substr(0,2)|0,n=2;a.length-n;n+=2)e+='%'+('0'+('0x'+a.substr(n,2)^r).toString(16)).slice(-2);p.replaceChild(document.createTextNode(decodeURIComponent(e)),c)}p.removeChild(t)}}catch(u){}}()/* ]]> */</script></p>
<p>Thomas A. Longstaff<br/>
CERT Coordination Center, Software Engineering Institute<br/>
Carnegie-Mellon University Pittsburgh, PA 15213 <a class="__cf_email__" href="/cdn-cgi/l/email-protection" data-cfemail="92e6f3fed2f1f7e0e6bcfde0f5">[email&#160;protected]</a><script data-cfhash='f9e31' type="text/rocketscript">/* <![CDATA[ */!function(t,e,r,n,c,a,p){try{t=document.currentScript||function(){for(t=document.getElementsByTagName('script'),e=t.length;e--;)if(t[e].getAttribute('data-cfhash'))return t[e]}();if(t&&(c=t.previousSibling)){p=t.parentNode;if(a=c.getAttribute('data-cfemail')){for(e='',r='0x'+a.substr(0,2)|0,n=2;a.length-n;n+=2)e+='%'+('0'+('0x'+a.substr(n,2)^r).toString(16)).slice(-2);p.replaceChild(document.createTextNode(decodeURIComponent(e)),c)}p.removeChild(t)}}catch(u){}}()/* ]]> */</script></p>
</address>
<ul>
<li><a href="#c0">Abstract</a></li>
<li><a href="#c1">1 Introduction</a></li>
<li><a href="#c2">2 Related Work</a></li>
<li><a href="#c3">3 Defining Self</a>
<ul>
<li><a href="#c31">3.1 Details</a></li>
</ul></li>
<li><a href="#c4">4 Experiments</a>
<ul>
<li><a href="#c41">4.1 Building a normal database</a></li>
<li><a href="#c42">4.2 Distinguishing Between Processes</a></li>
<li><a href="#c43">4.3 Anomalous Behavior</a></li>
</ul></li>
<li><a href="#c5">5 Discussion</a></li>
<li><a href="#c6">6 Conclusions</a></li>
<li><a href="#c7">7 Acknowledgments</a></li>
<li><a href="#c8">References</a></li>
</ul>
<h2><a name="c0"></a>Abstract</h2>
<p><em>A method for anomaly detection is introduced in which “normal” is deﬁned by short-range correlations in a process’ system calls. Initial experiments suggest that the deﬁnition is stable during normal behavior for standard UNIX programs. Further, it is able to detect several common intrusions involving <tt>sendmail</tt> and <tt>lpr</tt>. This work is part of a research program aimed at building computer security systems that incorporate the mechanisms and algorithms used by natural immune systems.</em></p>
<h2><a name="c1"></a>1 Introduction</h2>
<p>We are interested in developing computer security methods that are based on the way natural immune systems distinguish self from other. Such “artiﬁcial immune systems” would have richer notions of identity and protection than those afforded by current operating systems, and they could provide a layer of general-purpose protection to augment current computer security systems. An important prerequisite of such a system is an appropriate deﬁnition of self, which is the subject of this paper. We view the use of immune system inspired methods in computer security as complementary to more traditional cryptographic and deterministic approaches. By analogy, the speciﬁc immune response is a secondary mechanism that sits behind passive barriers (e.g., the skin and mucus membranes) and other innate responses (e.g., generalized inﬂammatory mechanisms). In related work, we studied a number of immune system models based on these secondary mechanisms [10, 13, 11] which provide the inspiration for the project described here.</p>
<p>The natural immune systemhas several propertiesthat we believe are important for robust computer security. These include the following: (1) detection is distributed and each copy of the detection system is unique, (2) detection is probabilistic and on-line, and (3) detectors are designed to recognize virtually any foreign particle, not just those that have been previously seen. These properties and their signiﬁcance are discussed in [11].</p>
<p>Previously, we developed a computer virus detection method based on these principles [11]. The method was implemented at the ﬁle-authentication level, and self was deﬁned statically in terms of ﬁles containing programs or other protected data. However, if we want to build a general-purpose protective capability we will need a more ﬂexible sense of self. One problem with this is that what we mean by self in a computer system seems at ﬁrst to be more dynamic than in the case of natural immune systems. For example, computer users routinely load updated software, edit ﬁles, run new programs, or change their personal work habits. New users and new machines are routinely added to computer networks. In each of these cases, the normal behavior of the system is changed, sometimes dramatically, and a successful deﬁnition of self will need to accommodate these legitimate activities. An additional requirement is to identify self in such a way that the deﬁnition is sensitive to dangerous foreign activities. Immunologically, this is known as the ability to distinguish between self and other. Too narrow a deﬁnition will result in many false positives, while too broad a deﬁnition of self will be tolerant of some unacceptable activities (false negatives).</p>
<p>This paper reports preliminary results aimed at establishing such a deﬁnition of self for Unix processes, one in which self is treated synonymously with normal behavior. Our experiments show that short sequences of system calls in running processes generate a stable signature for normal behavior. The signature has low variance over a wide range of normal operating conditions and is speciﬁc to each different kind of process, providing clear separation between different kinds of programs. Further, the signature has a high probability of being perturbed when abnormal activities, such as attacks or attack attempts, occur. These results are signiﬁcant because most prior published work on intrusion detection has relied on either a much more complex deﬁnition of normal behavior or on prior knowledge about the speciﬁc form of intrusions. We suggest that a simpler approach, such as the one described in this paper, can be effective in providing partial protection from intrusions. One advantage of a simple deﬁnition for normal behavior is the potential for implementing an on-line monitoring system that runs in real-time.</p>
<h2><a name="c2"></a>2 Related Work</h2>
<p>There are two basic approaches to intrusion detection [16, 15]: misuse intrusion detection and anomaly intrusion detection. In misuse intrusion detection, known patterns of intrusion (intrusion signatures) are used to try to identify intrusions when they happen. In anomaly intrusion detection, it is assumed that the nature of the intrusion is unknown, but that the intrusion will result in behavior different from that normally seen in the system. Many detection systems combine both approaches, a good example being IDES [18, 4, 8]. In this paper we are concerned only with anomaly intrusion detection.</p>
<p>Most previous work on anomaly intrusion detection has determined proﬁles for user behavior. Intrusions are detected when a user behaves out of character. These anomalies are detected by using statistical proﬁles, as in IDES [18, 4, 8], inductive pattern generation, as in TIM [19], or neural networks [12]. Generation of user proﬁles by such methods requires an audit trail of actions for each user. These are typically slowly adaptive, changing proﬁles gradually to accommodate changing user behavior. Abrupt changes in behavior are ﬂagged as irregular and identiﬁed with intrusions.</p>
<p>An alternative approach is taken by Fink, Levitt and Ko [9, 14]. Instead of trying to build up normal user proﬁles, they focus on determining normal behavior for privileged processes, those that run as root. They deﬁne normal behavior using a program speciﬁcation language, in which the allowed operations (system calls and their parameters) of a process are formally speciﬁed. Our approach is similar to theirs, in that we consider processes that run as root. However, it differs in that we use a much simpler representation of normal behavior. We rely on examples of normal runs rather than formal speciﬁcation of a program’s expected behavior, and we ignore parameter values. An advantage of our approach is that we do not have to determine a behavioral speciﬁcation from the program code; we simply accumulate it by tracing normal runs of the program.</p>
<h2><a name="c3"></a>3 Deﬁning Self</h2>
<p>Program code stored on disk is unlikely to cause damage until it runs. System damage is caused by running programs that execute system calls. Thus, we restrict our attention to system calls in running processes. Further, we consider only privileged processes. Monitoring privileged processes has several advantages over monitoring user proﬁles[14]. Root processes are more dangerous than user processes because they have access to more parts of the computer system. They have a limited range of behavior, and their behavior is relatively stable over time. Also, root processes, especially those that listen to a particular port, constitute a natural boundary with respect to external probes and intrusions. However, there are some limitations. For example, it will be difﬁcult to detect an intruder masquerading as another user (having previously obtained a legal password).</p>
<p>Every program implicitly speciﬁes a set of system call sequences that it can produce. These sequences are determined by the ordering of system calls in the set of the possible execution paths through the program text. During normal execution, some subset of these sequences will be produced. For any nontrivial program, the theoretical sets of system call sequences will be huge, and it is likely that any given execution of a program will produce a complete sequence of calls that has not been observed. However, the local (short range) ordering of system calls appears to be remarkably consistent, and this suggests a simple deﬁnition of self, or normal behavior.</p>
<p>We deﬁne normal behavior in terms of short sequences of system calls in a running process, currently sequences of lengths 5, 6, and 11. The overallidea is to build up a separate database of normal behaviorfor each processof interest. The database willbe speciﬁcto a particular architecture,software version and conﬁguration, local administrative policies, and usage patterns. Given the large variability in how individual systems are currently conﬁgured, patched, and used, we conjecture that these individual databases will provide a unique deﬁnition of self for most systems. Once a stable database is constructed for a given process, the database can be used to monitor the process’ ongoing behavior. The sequences of system calls form the set of normal patterns for the database, and abnormal sequences indicate anomalies in the running process.</p>
<p>This deﬁnition of normal behavior ignores many aspects of process behavior, such as the parameter values passed to system calls, timing information, and instruction sequences between system calls. Certain intrusions might only be detectable by examing other aspects of a process’s behavior, and so we mightneed to consider them later. Our philosophy is to see how far we can go with the simple assumption.</p>
<h3><a name="c31"></a>3.1 Details</h3>
<p>There are two stages to the proposed algorithm. In the ﬁrst stage, we scan traces of normal behavior and build up a database of characteristic normal patterns (observed sequences of system calls). Forks are traced individually, and their traces are included as part of normal.<sup><a href="#f1" name="b1">1</a></sup> In the second stage, we scan new traces that might contain abnormal behavior, looking for patterns not present in the normal database. In our current implementation, analysis of traces is performed off-line.</p>
<p>To build up the database, we slide a window of size <img src="/img/cache/a31a860e7a59c7616c1515ec3ae652a6.gif" alt="k+1" valign="middle"/> across the trace of system calls and record which calls follow which within the sliding window. Suppose we choose <img src="/img/cache/9d8980d95018cffda6b0d77684ba1523.gif" alt="k=3" valign="middle"/> and are given the following sequence of system calls to deﬁne normal behavior:</p>
<p>open, read, mmap, mmap, open, getrlimit, mmap, close</p>
<p>As we slide the window across the sequence, we record for each call the call that follows it at position 1, at position 2, and so forth, up to position k. For the ﬁrst window, from index 1 in the sequence to index 4, the following database is produced:</p>
<table summary="">
<tr><th>call</th><th>position 1</th><th>position 2</th><th>position 3</th></tr>
<tr><td>open</td><td>read</td><td>mmap</td><td>mmap</td></tr>
<tr><td>read</td><td>mmap</td><td>mmap</td><td>&nbsp;</td></tr>
<tr><td>mmap</td><td>mmap</td><td>&nbsp;</td><td>&nbsp;</td></tr>
</table>
<p>Whenever a call occurs more than once, it can be followed by several different possible calls. These are all recorded. After sliding the window across the complete sequence, we produce this expanded database:</p>
<table summary="">
<tr><th>call</th><th>position 1</th><th>position 2</th><th>position 3</th></tr>
<tr><td>open</td><td>read, getrlimit</td><td>mmap</td><td>mmap, close</td></tr>
<tr><td>read</td><td>mmap</td><td>mmap</td><td>open</td></tr>
<tr><td>mmap</td><td>mmap, open, close</td><td>open, getrlimit</td><td>getrlimit, mmap</td></tr>
<tr><td>getrlimit</td><td>mmap</td><td>close</td><td>&nbsp;</td></tr>
<tr><td>close</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
</table>
<p>Once we have the database of normal patterns, we check new traces against it using the same method. We slide a window of size <img src="/img/cache/a31a860e7a59c7616c1515ec3ae652a6.gif" alt="k+1" valign="middle"/> across the new trace, determining if the sequence of system calls differs from that recorded in the normal database. In our work to date, we simply test for the presence or absence of legal sequences. As an example, suppose that we had constructedthe abovedatabase and were given a new trace of calls, differing at one location from the normal sequence (open replaces mmap as the fourth call in the sequence):</p>
<p>open, read, mmap, open, open, getrlimit, mmap, close</p>
<p>This trace would generate 4 mismatches, because:</p>
<ul>
<li>open is not followed by open at position 3,</li>
<li>read is not followed by open at position 2,</li>
<li>open is not followed by open at position 1, and</li>
<li>open is not followed by getrlimit at position 2.</li>
</ul>
<p>We record the number of mismatches as a percentage of the total possible number of mismatches. The maximum number of pairwise mismatches for a sequence of length <img src="/img/cache/d20caec3b48a1eef164cb4ca81ba2587.gif" alt="L" valign="middle"/> with a lookahead of <img src="/img/cache/8ce4b16b22b58894aa86c421e8759df3.gif" alt="k" valign="middle"/> is:</p>
<p><img src="/img/cache/13094e63621afeb83a6f41f2f4f2a6b7.gif" alt="k(L-k)+(k-1)+(k-2)+\dots+1=k(L-(k+1)/2)." valign="middle"/></p>
<p>In our example trace, <img src="/img/cache/8a4c66c39646d5ecd8e2f6704a9e8914.gif" alt="L=8, k=3" valign="middle"/>, and we have 4 mismatches. From the above formula, we get a maximum database size of 18, giving a 22% miss rate. Mismatches are the only observable that we use to distinguish normal from abnormal.</p>
<p>This simple algorithm can be efﬁciently implemented to run in <img src="/img/cache/33697ce7dfa48ba80980d298c8089378.gif" alt="O(N)" valign="middle"/> time, where <img src="/img/cache/8d9c307cb7f3c4a32822a51922d1ceaa.gif" alt="N" valign="middle"/>is the length of the trace (in terms of system calls). For example, our current implementation analyzes traces at an approximate rate of 1250 system calls per second.</p>
<h2><a name="c4"></a>4 Experiments</h2>
<p>In the previous section we introduced a deﬁnition for normal behavior, based on short sequences of system calls. The usefulness of the deﬁnition will largely be determined by the answers to the following questions:</p>
<ul>
<li>What size database do we need to capture normal behavior?</li>
<li>What percentage of possible system call sequences is covered by the database of “normal” system call sequences?</li>
<li>Does our deﬁnition of normal behavior distinguish between different kinds of programs?</li>
<li>Does our deﬁnition of normal detect anomalous behavior?</li>
</ul>
<p>This section reports our preliminary answers to these questions. In these experiments, we focus on <tt>sendmail</tt> although we report some data for <tt>lpr</tt>. The <tt>sendmail</tt> program is sufﬁciently varied and complex to provide a good initial test, and there are several documented attacks against <tt>sendmail</tt> that can be used for testing. If we are successful with <tt>sendmail</tt> we conjecture that we will be successful with many other privileged Unix processes. All of our data to date have been generated on Sun SPARC stations running unpatched versions of SunOS 4.1.1 and 4.1.4, using the included <tt>sendmail</tt>. The <tt>strace</tt> package, version 3.0, was used to gather information on system calls.</p>
<h3><a name="c41"></a>4.1 Building a normal database</h3>
<p>Although the idea of collecting traces of normal behavior sounds simple, there are a number of decisions that must be made regarding how much and what kind of normal behavior is appropriate. Speciﬁcally, should we generate an artiﬁcial set of test messages that exercises all normal modes of <tt>sendmail</tt> or should we monitor real user mail and hope that it covers the full spectrum of normal (more in the spirit of our approach)? This question is especially relevant for <tt>sendmail</tt> because its behavior is so varied. If we fail to capture all the sources of legal variations, then it will be easier to detect intrusions and be an unfair test because of false positives. We elected to use a suite of 112 artiﬁcially constructed messages, which included as many normal variations as possible. These 112 messages produced a a combined trace length of over 1.5 million system calls. For a window size of 6, the 112 messages produced a database with 6 1500 entries, where one entry corresponds to a single pair of system calls with a lookahead value (e.g., read is a legal successor to open at position 1).</p>
<p>Once the normal database is deﬁned, the next decision is howto measurenew behaviorand determine if it is normal or abnormal. The easiest and most natural measure is simply to count the number of mismatches between a new trace and the database. We report these counts both as a raw number and as a percentage of the total number of matches performed in the trace, which reﬂects the length of the trace. Ideally, we would like these numbers to be zero for new examples of normal behavior, and for them to jump signiﬁcantly when abnormalities occur. In a real system, a threshold value would need to be determined, below which a behavior is said to be normal, and above which it is deemed anomalous. In this study, we simply report the numbers, because we are not taking any action or making a binary decision based on them. Because our normal database covers most variations in normal, any mismatches are in principle signiﬁcant.</p>
<p>Returning to our earlier questions, the size of the normal database is of interest for two reasons. First, if the database is small then it deﬁnes a compact signature for the running process that would be practical to check in real-time while the process is active. Conversely, if the database is large then our approach will be too expensive to use for on-line monitoring. Second, the size of the normal database gives an estimate of how much variability there is in the normal behavior of <tt>sendmail</tt>. This consideration is crucial because too much variability in normal would preclude detecting anomalies. In the worst case, if all possible sequences of length 6 show up as legal normal behavior, then no anomalies could ever be detected. A related question is how much normal behavior should be sampled to provide good coverage of the set of allowable sequences. We used the following procedure to build the normal database:<sup><a href="#f2" name="b2">2</a></sup></p>
<ol>
<li>Enumerate potential sources of variation for normal <tt>sendmail</tt> operation.</li>
<li>Generate example mail messages that cause <tt>sendmail</tt> to exhibit these variations.</li>
<li>Build a normal data base from the sequences produced by step 2.</li>
<li>Continue generating normal mail messages, recording all mismatches and adding them to the normal database as they occur.</li>
</ol>
<p>We considered variations in message length, number of messages, message content (text, binary, encoded, encrypted), message subject line, sender/receiver and mailers. We also looked at the effects of forwarding, bounced mail and queuing. Lastly, we considered the effects of all these variations in the cases of remote and local delivery. For each test, we generated three databases, one for each different window size (5, 6 and 11). Each database incorporates all of the features described above, producing zero mismatches for mail with any of these features.</p>
<table summary="Table 1. Types and number of mail messages used to generate the normal database for sendmail.">
<tr><th>Type of Behavior</th><th># of msgs.</th></tr>
<tr><td>message length</td><td>12</td></tr>
<tr><td>number of messages</td><td>70</td></tr>
<tr><td>message content</td><td>6</td></tr>
<tr><td>subject</td><td>2</td></tr>
<tr><td>sender/receiver</td><td>4</td></tr>
<tr><td>different mailers</td><td>4</td></tr>
<tr><td>forwarding</td><td>4</td></tr>
<tr><td>bounced mail</td><td>4</td></tr>
<tr><td>queuing</td><td>4</td></tr>
<tr><td>vacation</td><td>2</td></tr>
<tr><td>total</td><td>112</td></tr>
</table>
<p><strong>Table 1. Types and number of mail messages used to generate the normal database for sendmail.</strong></p>
<p>Table 1 shows how many messages of each type were used to generate the normal databases. We began with message length and tried 12 different message lengths, ranging from 1 line to 300,000 bytes. From this, we selected the shortest length that produced the most varied pattern of system calls (50,000 bytes), and then used that as the standard message length for the remaining test messages. Similarly, with the number of messages in a sendmail run, we ﬁrst sent 1 message and traced <tt>sendmail</tt> then we sent 5 messages, tracing <tt>sendmail</tt>, and so forth, up to 20 messages. This was intended to test <tt>sendmail</tt>’s response to bursts of messages. We tested message content by sending messages containing ascii text, uuencoded data, gzipped data, and a pgp encrypted ﬁle. In each case, a number of variations was tested and a single default was selected before moving on to the next stage. These messages constituted our corpus of normal behavior. We reran this set of standard messages on each different OS and <tt>sendmail.cf</tt> variant that we tried, thus generating a normal database that was tailored to the exact operating conditions under which <tt>sendmail</tt> was running. Of the features considered, the following seemed to have little or no effect: the number of messages, message content, subject line, senders/receivers, mailers and queuing. Two more unusual features, forwarded mail and bounced mail, affected remote traces far less than local traces.</p>
<p>Figure 1 shows how new patterns are added to the database over time during a normal <tt>sendmail</tt> run. The data shown are for 10,000 system calls worth of behavior, but we have also performed runs out to 1.5 million system calls (data not shown), with essentially zero mismatches. Overall, the variability in the behavior of <tt>sendmail</tt> at the system call level is much smaller than we expected.</p>
<p>Finally, we ask what percentage of the total possible patterns (for sequences of length 6) is covered by the normal database. For example, if the database is completely full (all possible patterns have been recorded as normal) by 3000 system calls, then it would hardly be surprising that no new patterns are seen over time. However, as we discussed earlier, such variability would be useless for identifying anomalous behavior. Consequently, the goal is to ﬁnd a database that is small with respect to the space of possible patterns. Our initial data here are encouraging. We estimate that the <tt>sendmail</tt> database described above covers about <img src="/img/cache/a725e3dbb5758ed2ff301d37f5d66e72.gif" alt="5\times 10^{-5}%" valign="middle"/> of the total possible patterns of system calls (that is, sequences built from all possible system calls, about 180 for Unix, not just those invoked by <tt>sendmail</tt>), an extremely small fraction. This ﬁgure is somewhat misleading, however, because it is unlikely that the <tt>sendmail</tt> program is capable of generating many of these sequences. The most accurate comparison would be against a database that contained all the patterns that <tt>sendmail</tt> could possibly produce. This would require a detailed analysis of the <tt>sendmail</tt> source code, an area of future investigation.</p>
<table summary="Table 2. Distinguishing sendmail from other processes. Each column lists two numbers: the percentage of abnormal sequences (labeled %) and the number of abnormal sequences (labeled #) in one typical trace of each process (when compared against the normal database for sendmail). The columns labeled 5, 6 and 11 refer to the sequence length (window size) used for analysis. The sendmail data show no misses, because sendmail is being compared against its own database.">
<tr><td rowspan="2">Process</td><td colspan="2">5</td><td colspan="2">6</td><td colspan="2">11</td></tr>
<tr><td>%</td><td>#</td><td>%</td><td>#</td><td>%</td><td>#</td></tr>
<tr><td>sendmail</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td></tr>
<tr><td>ls</td><td>6.9</td><td>23</td><td>8.9</td><td>34</td><td>13.9</td><td>93</td></tr>
<tr><td>ls -l</td><td>30.0</td><td>239</td><td>32.1</td><td>304</td><td>38.0</td><td>640</td></tr>
<tr><td>ls -a</td><td>6.7</td><td>23</td><td>8.3</td><td>34</td><td>13.4</td><td>93</td></tr>
<tr><td>ps</td><td>1.2</td><td>35</td><td>8.3</td><td>282</td><td>13.0</td><td>804</td></tr>
<tr><td>ps -ux</td><td>0.8</td><td>45</td><td>8.1</td><td>564</td><td>12.9</td><td>1641</td></tr>
<tr><td>ﬁnger</td><td>4.6</td><td>21</td><td>4.9</td><td>27</td><td>5.7</td><td>54</td></tr>
<tr><td>ping</td><td>13.5</td><td>56</td><td>14.2</td><td>70</td><td>15.5</td><td>131</td></tr>
<tr><td>ftp</td><td>28.8</td><td>450</td><td>31.5</td><td>587</td><td>35.1</td><td>1182</td></tr>
<tr><td>pine</td><td>25.4</td><td>1522</td><td>27.6</td><td>1984</td><td>30.0</td><td>3931</td></tr>
<tr><td>httpd</td><td>4.3</td><td>310</td><td>4.8</td><td>436</td><td>4.7</td><td>824</td></tr>
</table>
<p><strong>Table 2. Distinguishing sendmail from other processes. Each column lists two numbers: the percentage of abnormal sequences (labeled %) and the number of abnormal sequences (labeled #) in one typical trace of each process (when compared against the normal database for sendmail). The columns labeled 5, 6 and 11 refer to the sequence length (window size) used for analysis. The sendmail data show no misses, because sendmail is being compared against its own database.</strong></p>
<h3><a name="c42"></a>4.2 Distinguishing Between Processes</h3>
<p>To determine how the behavior of <tt>sendmail</tt> compares with that of other processes, we tested several common processes against the normal <tt>sendmail</tt> database with 1500 entries. Table 2 compares normal traces of several common processes with those of <tt>sendmail</tt>. These processes have a signiﬁcant number of abnormal sequences, approximately, 5–32% for sequences of length 6, because the actions they perform are considerably different from those of <tt>sendmail</tt>. We also tested the normal database for lpr and achieved similar results (data not shown). lpr shows even more separation than that shown in Figure 2, presumably because it is a smaller program with more limited behavior. These results suggest that the behavior of different processes is easily distinguishable using sequence information alone.</p>
<h3><a name="c43"></a>4.3 Anomalous Behavior</h3>
<p>We generated traces of three types of behavior that differ from that of normal <tt>sendmail</tt>: traces of successful <tt>sendmail</tt> intrusions, traces of sendmail intrusion attempts that failed, and traces of error conditions. In each of these cases, we compared the trace with the normal <tt>sendmail</tt> database and recorded the number of mismatches. In addition,we tested one successfullpr intrusion and compared its trace with a normal database for <tt>lpr</tt>. Table 3 shows the results of these comparisons. Each row in the table reports data for one typical trace. In most cases, we have conducted multiple runs of the intrusion with identical or nearly identical results.</p>
<div align="center">
<img src="img/afo00/fig1.gif" alt="Figure 1. Building a normal database. The graph shows how many new patterns are added to the database over time. By running our artiﬁcially constructed set of standard messages, a wide variety of normal behavior is seen in the early part of the run (out to about 3000 system calls). After this time, virtually no new patterns are encountered under normal sendmail conditions. These data are a concatenation of the logs used to generate our normal database."/>
<p><strong>Figure 1. Building a normal database. The graph shows how many new patterns are added to the database over time. By running our artiﬁcially constructed set of standard messages, a wide variety of normal behavior is seen in the early part of the run (out to about 3000 system calls). After this time, virtually no new patterns are encountered under normal sendmail conditions. These data are a concatenation of the logs used to generate our normal database.</strong></p>
</div>
<p>To date, we have been able to execute and trace four attacks: <tt>sunsendmailcp</tt> [1], a syslog attack script [2, 7], a decode alias attack, and <tt>lprcp</tt> [3].</p>
<p>The <tt>sunsendmailcp</tt> script uses a special command line option to cause <tt>sendmail</tt> to append an email message to a ﬁle. By using this script on a ﬁle such as <tt>/.rhosts</tt>, a local user may obtain root access.</p>
<p>The syslog attack uses the syslog interface to overﬂow a buffer in <tt>sendmail</tt>. A message is sent to the <tt>sendmail</tt> on the victim machine, causing it to log a very long, specially created error message. The log entry overﬂows a buffer in <tt>sendmail</tt>, replacing part of the <tt>sendmail</tt>’s running image with the attacker’s machine code. The new code is then executed,causing the standard I/O of a root-owned shell to be attached to a port. The attacker may then attach to this port at her leisure. This attack can be run either locally or remotely, and we have tested both modes. We also varied the number of commands issued as root after a successful attack.</p>
<p>In older <tt>sendmail</tt> installations, the alias database contains an entry called “decode,” which resolves to <tt>uudecode</tt>, a UNIX program that converts a binary ﬁle encoded in plain text into its original form and name. <tt>uudecode</tt> respects absolute ﬁlenames, so if a ﬁle "bar.uu" says that the original ﬁle is "/home/foo/.rhosts," then when <tt>uudecode</tt> is given “bar.uu,” it will attempt to create foo’s <tt>.rhosts</tt> ﬁle. <tt>sendmail</tt> will generally run <tt>uudecode</tt> as the semi-privileged user daemon, so email sent to decode cannot overwrite any ﬁle on the system; however, if a ﬁle is world-writable, the decode alias entry allows these ﬁles to be modiﬁed by a remote user.</p>
<table summary="Table 3. Detecting Anomalies. The table shows the results of tracing sendmail and lpr during various anomalous situations: successful intrusions (sunsendmailcp, syslog, decode, and lprcp), unsuccessful intrusions, (sm565a and sm5x), and abnormal errors (forward loop). The data for the syslogd attack show the results of tracing sendmail (rather than tracing syslogd itself). The % column indicates the percentage of abnormal sequences in one typical intrusion, and the # column indicates the number of abnormal sequences.">
<tr><td rowspan="2">Anomaly</td><td colspan="2">5</td><td colspan="2">6</td><td colspan="2">11</td></tr>
<tr><td>%</td><td>#</td><td>%</td><td>#</td><td>%</td><td>#</td></tr>
<tr><td>sunsendmailcp</td><td>3.8</td><td>72</td><td>4.1</td><td>95</td><td>5.2</td><td>215</td></tr>
<tr><td colspan="7">syslog:</td></tr>
<tr><td>remote 1</td><td>3.9</td><td>361</td><td>4.2</td><td>470</td><td>5.1</td><td>1047</td></tr>
<tr><td>remote 2</td><td>1.4</td><td>111</td><td>1.5</td><td>137</td><td>1.7</td><td>286</td></tr>
<tr><td>local 1</td><td>3.0</td><td>235</td><td>4.2</td><td>398</td><td>4.0</td><td>688</td></tr>
<tr><td>local 2</td><td>4.1</td><td>307</td><td>3.4</td><td>309</td><td>5.3</td><td>883</td></tr>
<tr><td>decode</td><td>0.3</td><td>21</td><td>0.3</td><td>24</td><td>0.3</td><td>57</td></tr>
<tr><td>lprcp</td><td>1.1</td><td>7</td><td>1.4</td><td>12</td><td>2.2</td><td>31</td></tr>
<tr><td>sm565a</td><td>0.4</td><td>27</td><td>0.4</td><td>36</td><td>0.6</td><td>89</td></tr>
<tr><td>sm5x</td><td>1.4</td><td>110</td><td>1.7</td><td>157</td><td>2.7</td><td>453</td></tr>
<tr><td>forward loop</td><td>1.6</td><td>43</td><td>1.8</td><td>58</td><td>2.3</td><td>138</td></tr>
</table>
<p><strong>Table 3. Detecting Anomalies. The table shows the results of tracing sendmail and lpr during various anomalous situations: successful intrusions (sunsendmailcp, syslog, decode, and lprcp), unsuccessful intrusions, (sm565a and sm5x), and abnormal errors (forward loop). The data for the syslogd attack show the results of tracing sendmail (rather than tracing syslogd itself). The % column indicates the percentage of abnormal sequences in one typical intrusion, and the # column indicates the number of abnormal sequences.</strong></p>
<p>The <tt>lprcp</tt> attack script uses <tt>lpr</tt> to replace the contents of an arbitrary ﬁle with those of another. This exploit uses the fact that older versions of <tt>lpr</tt> use only 1000 different names for printer queue ﬁles, and they do not remove the old queue ﬁles before reusing them. The attack consists of getting <tt>lpr</tt> to place a symbolic link to the victim ﬁle in the queue, incrementing <tt>lpr</tt>’s counter 1000 times, and then printing the new ﬁle, overwriting the victim ﬁle’s contents.</p>
<p>The results for these four attacks are shown in Table 3. The <tt>sunsendmailcp</tt> exploit is clearly detected with 5.2% anomalous sequences (for length 11). Likewise, the syslog attack is clearly detected in every run, with the anomalous sequence rate varying between 1.7% and 5.3%, for a sequence window of 6. The decode attack is less detectable at 0.3%, and the <tt>lpr</tt> attack is detected at 2.2%.</p>
<p>A second source of anomalous behavior comes from unsuccessful intrusion attempts. We tested two remote attack scripts, called <tt>sm565a</tt> and <tt>sm5x</tt> [5, 6]. SunOS 4.1.4 has patches that prevent these particular intrusions. The results are shown in Table 3. Overall, the percentage of abnormal sequences is on the low end of the range for successful attacks.</p>
<p>Error conditions provide a third source of anomalous behavior. In general, it would be desirable if error conditions produced less deviation from normal than intrusions but were still detectable. For the one case we have studied, a local forwarding loop, this is what we observed (excluding the decode and lpr exploits). A forwarding loop occurs when a set of <tt>$HOME/.forward</tt> ﬁles form a logical circle. We considered the simplest case, with the following setup:</p>
<table summary="">
<tr><th>Email address</th><th>.forward ﬁle</th></tr>
<tr><td><a class="__cf_email__" href="/cdn-cgi/l/email-protection" data-cfemail="a7c1c8c8e7cfc8d4d396">[email&#160;protected]</a><script data-cfhash='f9e31' type="text/rocketscript">/* <![CDATA[ */!function(t,e,r,n,c,a,p){try{t=document.currentScript||function(){for(t=document.getElementsByTagName('script'),e=t.length;e--;)if(t[e].getAttribute('data-cfhash'))return t[e]}();if(t&&(c=t.previousSibling)){p=t.parentNode;if(a=c.getAttribute('data-cfemail')){for(e='',r='0x'+a.substr(0,2)|0,n=2;a.length-n;n+=2)e+='%'+('0'+('0x'+a.substr(n,2)^r).toString(16)).slice(-2);p.replaceChild(document.createTextNode(decodeURIComponent(e)),c)}p.removeChild(t)}}catch(u){}}()/* ]]> */</script></td><td><a class="__cf_email__" href="/cdn-cgi/l/email-protection" data-cfemail="1f7d7e6d5f77706c6b2d">[email&#160;protected]</a><script data-cfhash='f9e31' type="text/rocketscript">/* <![CDATA[ */!function(t,e,r,n,c,a,p){try{t=document.currentScript||function(){for(t=document.getElementsByTagName('script'),e=t.length;e--;)if(t[e].getAttribute('data-cfhash'))return t[e]}();if(t&&(c=t.previousSibling)){p=t.parentNode;if(a=c.getAttribute('data-cfemail')){for(e='',r='0x'+a.substr(0,2)|0,n=2;a.length-n;n+=2)e+='%'+('0'+('0x'+a.substr(n,2)^r).toString(16)).slice(-2);p.replaceChild(document.createTextNode(decodeURIComponent(e)),c)}p.removeChild(t)}}catch(u){}}()/* ]]> */</script></td></tr>
<tr><td><a class="__cf_email__" href="/cdn-cgi/l/email-protection" data-cfemail="d4b6b5a694bcbba7a0e6">[email&#160;protected]</a><script data-cfhash='f9e31' type="text/rocketscript">/* <![CDATA[ */!function(t,e,r,n,c,a,p){try{t=document.currentScript||function(){for(t=document.getElementsByTagName('script'),e=t.length;e--;)if(t[e].getAttribute('data-cfhash'))return t[e]}();if(t&&(c=t.previousSibling)){p=t.parentNode;if(a=c.getAttribute('data-cfemail')){for(e='',r='0x'+a.substr(0,2)|0,n=2;a.length-n;n+=2)e+='%'+('0'+('0x'+a.substr(n,2)^r).toString(16)).slice(-2);p.replaceChild(document.createTextNode(decodeURIComponent(e)),c)}p.removeChild(t)}}catch(u){}}()/* ]]> */</script></td><td><a class="__cf_email__" href="/cdn-cgi/l/email-protection" data-cfemail="1a7c75755a7275696e2b">[email&#160;protected]</a><script data-cfhash='f9e31' type="text/rocketscript">/* <![CDATA[ */!function(t,e,r,n,c,a,p){try{t=document.currentScript||function(){for(t=document.getElementsByTagName('script'),e=t.length;e--;)if(t[e].getAttribute('data-cfhash'))return t[e]}();if(t&&(c=t.previousSibling)){p=t.parentNode;if(a=c.getAttribute('data-cfemail')){for(e='',r='0x'+a.substr(0,2)|0,n=2;a.length-n;n+=2)e+='%'+('0'+('0x'+a.substr(n,2)^r).toString(16)).slice(-2);p.replaceChild(document.createTextNode(decodeURIComponent(e)),c)}p.removeChild(t)}}catch(u){}}()/* ]]> */</script></td></tr>
</table>
<p>Although forwarding loops are not malicious, they can adversely affect machine performance, as hundreds of messages are bounced from machine to machine. Results are reported in Table 3. They differ from normal by a small, yet clear, percentage (2.3%).</p>
<h2><a name="c5"></a>5 Discussion</h2>
<p>These preliminary experiments suggest that short sequences of system calls deﬁne a stable signature that can detect some common sources of anomalous behavior in <tt>sendmail</tt> and <tt>lpr</tt>. Because our measure is easy to compute and is relatively modest in storage requirements, it could be plausibly implemented as an on-line system, in which the kernel checked each system call made by processes running as root. Under this scheme, each site would generate its own normal database, based on the local software/hardware conﬁguration and usage patterns. This could be achieved either with a standard set of artiﬁcial messages, such as those we use to build our normal database, or it could be completely determined by local usage patterns. It is likely that some combination of the two would be most effective.</p>
<p>The data reported in this paper are preliminary. In addition to testing other processes, especially those that are common routes for intrusion, we would like to extend our <tt>sendmail</tt> experiments in several ways. These include: testing additional <tt>sendmail</tt> exploits, conducting systematic runs on common <tt>sendmail</tt> and <tt>sendmail.cf</tt> variants, and testing the effect of other system conﬁgurations on the normal behavior of <tt>sendmail</tt>. Another area for further study is the database of normal behavior, for example, how do we choose what behavior to trace? This is especially relevant for sendmail because its behavior is so varied. If we fail to capture all the sources of legal variation, then we will be subject to false positives. On the other hand, if we allow different databases at different sites, then some variation would be desirable both as customizations to local conditions and to satisfy the uniqueness principle stated earlier. Finally, we would like to study the normal behavior of <tt>sendmail</tt> running on a regularly used mail server. Such real-world data would help conﬁrm the nature of <tt>sendmail</tt>’s normal behavior in practice, especially when compared with our set of artiﬁcial messages.</p>
<p>Our approach is predicated on two important properties: (1) the sequence of system calls executed by a program is locally consistent during normal operation, and (2) some unusual short sequences of system calls will be executed when a security hole in a program is exploited. We believe that there is a good chance that the former condition will be met by many programs, simply because the code of most programs is static, and system calls occur at ﬁxed places within the code. Conditionals and function calls will change the relative orderings of the invoked system calls but not necessarily add variation to short-range correlations. We are also optimistic about the second property. If a program enters an unusual error state during an attempted break-in, and if this error condition executes a sequence of system calls that is not already covered by our normal database, we are likely to notice the attack. Also, if code is replaced inside a running program by an intruder, it would likely execute a sequence of system calls not in the normal database, and we would expect to see some misses. Finally, it is highly likely that a successful intruder will need to fork a new process in order to take advantage of the system. This fork, when it occurs, should be detectable.</p>
<p>However, if an intrusion does not ﬁt into either of these two categories, our method will almost certainly miss it under the current deﬁnition of normal. For example, we do not expect to detect race condition attacks. Typically, these types of intrusions involve stealing a resource (such as a ﬁle) created by a program running as root, before the program has had a chance to restrict access to the resource. If the root process does not detect an unusual error, a normal set of system calls will be made, defeating our method. This is an important avenue of attack, one that will require a revised deﬁnition of “self.” A second kind of intrusion that we will likely miss is the case of an intruder using another user’s account. User proﬁles can potentially provide coverage for this classof intrusions which are not likely to be detectable in root processes. Although the method we describe here will not provide a cryptographicallystrong or completely reliable discriminator between normal and abnormal behavior, it could potentially provide a lightweight, real-time tool for continuously checking executing code based on frequency of execution.</p>
<p>To achieve reliable discrimination, we need to ensure that our method of ﬂagging sequences as abnormal does not produce too many false negatives or false positives. Currently, we record both the number of absolute misses (of a monitored process against the normal database) as well as the percentage of misses (out of the total number of calls in a trace). Most of the exploits we have studied are very short in terms of the length of time the anomalous behavior takes place. There might be other more appropriate measures than the two we have used, especially in an on-line system, where the length of the trace would be indeﬁnitely long. A related question is the choice of pattern matching rule. We currently monitor only the presence or absence of patterns, not their relative frequency. However, there are many other matching criteria that could be tried. For example, we could represent the possible sequences of legal system calls as a Markov chain and deﬁne a criterion based on expected frequencies.</p>
<p>Returning to the larger question of how to build an artiﬁcial immune system for a computer, the work reported here constitutes an initial step in this direction. We have identiﬁed a signature for self that is stable across a wide variety of normal behavior and sensitive to some common sources of anomalies. Further, the deﬁnition provides a unique signature, or identity, for different kinds of processes. A second form of identity is possible because the method used to collect normal traces allows for a unique database at each site. Thus, a successful intrusion at one site would not necessarily be successful at all sites running the same software, and it would increase the chance of at least one site noticing an attack. Networks of computers are currently vulnerable to intrusions at least in part because of homogeneities in the software they run and the methods used to protect them. Our behavioral notion of identity goes well beyond a simple checksum, login, password, or IP address, because it considers dynamic patterns of activity rather than just static components.</p>
<p>However, the current system is a long way from having the capabilities of a natural immune system. We would like to use the deﬁnition of self presented here as the basis of future work along these lines. For example, we are not yet using any partial or approximate matching, such as that used by the immune system, and we are not using on-line learning, as in the case of afﬁnity maturation or negative selection. The immune system uses a host of different mechanisms for protection, each specialized to deal with a different type of intruder. A computer immune system could mimic this by incorporating additional mechanisms to provide more comprehensive security. For example, it might be possible to include Kumar’s misuse intrusion detection methods [17, 15] in the form of “memory cells” that store signatures of known intrusions. Finally, we have made no provision for the deﬁnition of self to change over time, although the natural immune system is continually replenishing its protective cells and molecules.</p>
<h2><a name="c6"></a>6 Conclusions</h2>
<p>This paper outlines an approach to intrusion detection that is quite different from other efforts to date, one that appears promising both in its simplicity and its practicality. We have proposed a method for deﬁning self for privileged Unix processes, in terms of normal patterns of short sequences of system calls. We have shown that the deﬁnition is compact with respect to the space of possible sequences, that it clearly distinguishes between different kinds of processes, and that it is perturbed by several different classes of anomalous, or foreign, behavior, allowing these anomalies to be detected. The results in this paper are preliminary, and there are attacks that our method is not able to detect. However, it is computationally efﬁcient to monitor short-range orderings of system calls, and this technique could potentially provide the basis for an on-line computer immune system consisting of several detection mechanisms, some inspired by the human immune system, and others derived from cryptographic techniques and more traditional intrusion detection systems.</p>
<h2><a name="c7"></a>7 Acknowledgments</h2>
<p>The authors thank David Ackley, Patrik D’haeseleer, Andrew Kosoresow, Arthur B. Maccabe, Kevin McCurley, and Nelson Minar for many helpful discussions, ideas, and criticisms. We also thank Jim Herbeck for supporting our neverending need to ﬁddle with our systems, and Larry Rodgers at the Computer Emergency Response Team (CERT) for helping with the syslog attack. The idea for developing a computer immune system grew out of an ongoing collaboration with Dr. Alan Perelson through the Santa Fe Institute, and some of the experiments were performed using the computer facilities and expertise at CERT. This work is supported by grants from the National Science Foundation (IRI-9157644), Ofﬁce of Naval Research (N00014-95-1-0364),and Interval Research Corporation.</p>
<h2><a name="c8"></a>References</h2>
<ol>
<li>[8LGM]. [8lgm]-advisory-16.unix.sendmail-6-dec-1994. http://www.8lgm.org/advisories.html.</li>
<li>[8LGM]. [8lgm]-advisory-22.unix.syslog.2-aug-1995. http://www.8lgm.org/advisories.html.</li>
<li>[8LGM]. [8lgm]-advisory-3.unix.lpr.19-aug-1991. http://www.8lgm.org/advisories.html.</li>
<li>D. Anderson, T. Frivold, and A. Valdes. Next-generation intrusion detection expert system (NIDES): A summary. Technical Report SRI–CSL–95–07, Computer Science Laboratory, SRI International, May 1995.</li>
<li>CERT. Sendmail v.5 vulnerability. ftp://info. cert.org/pub/cert advisories/CA-95:05.sendmail.vulnerabilities, February 22 1995.</li>
<li>CERT. Sendmail v.5 vulnerability. ftp://info.cert.org/pub/cert advisories/CA-95:08.sendmail.v.5.vulnerability, August 17 1995.</li>
<li>CERT. Syslog vulnerability — a workaround for sendmail. ftp://info.cert.org/pub/cert advisories/CA-95:13.syslog.vul, October 19 1995.</li>
<li>D. E. Denning. An intrusion detection model. In <em>IEEE Transactions on Software Engineering</em>, Los Alamos, CA, 1987. IEEE Computer Society Press.</li>
<li>G. Fink and K. Levitt. Property-based testing of privileged programs. In <em>Proceedings of the 10th Annual Computer Security Applications Conference</em>, pages 154–163, December 5–9 1994.</li>
<li>S. Forrest, B. Javornik, R. Smith, and A. Perelson. Using genetic algorithmsto explore pattern recognition in the immune system. <em>Evolutionary Computation</em>, 1(3):191–211, 1993.</li>
<li>S. Forrest, A. S. Perelson, L. Allen, and R. Cherukuri. Self-nonself discrimination in a computer. In <em>Proceedings of the 1994 IEEE Symposium on Research in Security and Privacy</em>, Los Alamos, CA, 1994. IEEE Computer Society Press.</li>
<li>K. L. Fox, R. R. Henning, J. H. Reed, and R. Simonian. A neural network approach towards intrusion detection. In <em>Proceedings of the 13th National Computer Security Conference</em>, pages 125–134, Washington, D.C., October 1990.</li>
<li>R. H. Hightower, S. Forrest, and A. S. Perelson. The baldwin effect in the immune system: learning by somatic hypermutation. In R. K. Belew and M. Mitchell, editors, <em>Individual Plasticity in Evolving Populations: Models and Algorithms</em>. Addison-Wesley, in press.</li>
<li>C. Ko, G. Fink, andK. Levitt. Automateddetectionof vulnerabilities in priviledged programs by execution monitoring. In <em>Proceedings of the 10th Annual Computer Security Applications Conference</em>, pages 134–144, December 5–9 1994.</li>
<li>S. Kumar. <em>Classiﬁcation and Detection of Computer Intrusions</em>. PhD thesis, Departmentof ComputerSciences, Purdue University, August 1995.</li>
<li>S. Kumar and E. H. Spafford. A software architecture to support misuse intrusion detection. In <em>Proceedings of the 18th National Information Security Conference</em>, pages 194–204, 1995.</li>
<li>S. Kumar and E. H. Spafford. A software architecture to support misuse intrusion detection. Technical Report CSD–TR–95–009, Department of Computer Sciences, Purdue University, March 1995.</li>
<li>T. Lunt, A. Tamaru, F. Gilham, R. Jagannathan, P. Neumann, H. Javitz, A. Valdes, and T. Garvey. A real-time intrusion detection expert system (IDES) — ﬁnal technical report. Computer Science Laboratory, SRI International, Menlo Park, California, February 1992.</li>
<li>H.S. Teng,K.Chen, andS. C.Lu. Security audit trail analysis using inductively generated predictive rules. In <em>Proceedings of the Sixth Conference on Artiﬁcial Intelligence Applications</em>, pages 24–29, Piscataway, New Jersey, March 1990. IEEE.</li>
</ol>
<hr size="1"/>
<p><a name="f1" href="#b1">1</a> Due to a limitation of our tracing package, we are not currently following virtual forks.</p>
<p><a name="f2" href="#b2">2</a> We followed a similar procedure to generate the normal database for lpr and obtained a database of 534 normal patterns.</p>
[<a style="" href="/lib/?lang=EN&amp;index=IM#afo00">Back to index</a>] [<a href="/lib/afo00.html#disqus_thread">Comments</a>]<br/> <div id="disqus_thread"></div>
<script type="text/rocketscript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'vxheaven'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
<div><small>By accessing, viewing, downloading or otherwise using this content you agree to be bound by the <a href="/agreement.php">Terms of Use</a>!</small> <small>vxheaven.org aka vx.netlux.org</small></div>
<div style="margin-top: 2px; float: left;" class="adsapeu">
<script type="text/rocketscript">
<!--
var _acic={dataProvider:10};(function(){var e=document.createElement("script");e.type="text/javascript";e.async=true;e.src="//www.acint.net/aci.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)})()
//-->
</script>
</div>
<script data-rocketsrc="http://www.google-analytics.com/urchin.js" type="text/rocketscript"></script><script type="text/rocketscript">try { _uacct = "UA-590608-1"; urchinTracker(); } catch(err) {}</script>
<div style="display: none;"><a href="/lib/index.php?lang=de&amp;id=afo00">de</a><a href="/lib/index.php?lang=en&amp;id=afo00">en</a><a href="/lib/index.php?lang=es&amp;id=afo00">es</a><a href="/lib/index.php?lang=it&amp;id=afo00">it</a><a href="/lib/index.php?lang=fr&amp;id=afo00">fr</a><a href="/lib/index.php?lang=pl&amp;id=afo00">pl</a><a href="/lib/index.php?lang=ru&amp;id=afo00">ru</a><a href="/lib/index.php?lang=ua&amp;id=afo00">ua</a></div>
</body>
</html>
